{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0c1c7b",
   "metadata": {
    "papermill": {
     "duration": 0.009364,
     "end_time": "2022-12-22T11:35:14.569844",
     "exception": false,
     "start_time": "2022-12-22T11:35:14.560480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because the datasets are SO large (especially the Multiome dataset), instead of running both parts of the project in one notebook (and risk Kaggle running out of storage space then resetting all progress), it is more convenient to separate the multiome and citeseq parts of the project, then later merge the predicted outputs from the two parts together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdd46f",
   "metadata": {
    "papermill": {
     "duration": 0.007616,
     "end_time": "2022-12-22T11:35:14.585346",
     "exception": false,
     "start_time": "2022-12-22T11:35:14.577730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook concerns itself with the CITEseq portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09eea0",
   "metadata": {
    "papermill": {
     "duration": 0.007308,
     "end_time": "2022-12-22T11:35:14.600690",
     "exception": false,
     "start_time": "2022-12-22T11:35:14.593382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First, all the basic imports and file names which may or may not be used is loaded in essentially as a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40927c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:35:14.618829Z",
     "iopub.status.busy": "2022-12-22T11:35:14.617875Z",
     "iopub.status.idle": "2022-12-22T11:35:29.023917Z",
     "shell.execute_reply": "2022-12-22T11:35:29.022153Z"
    },
    "papermill": {
     "duration": 14.419004,
     "end_time": "2022-12-22T11:35:29.027156",
     "exception": false,
     "start_time": "2022-12-22T11:35:14.608152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/conda/lib/python3.7/site-packages (3.7.0)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables) (2.8.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tables) (21.3)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from tables) (1.21.6)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tables) (3.0.9)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e1fc62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-22T11:35:29.045544Z",
     "iopub.status.busy": "2022-12-22T11:35:29.045025Z",
     "iopub.status.idle": "2022-12-22T11:35:30.567539Z",
     "shell.execute_reply": "2022-12-22T11:35:30.565793Z"
    },
    "papermill": {
     "duration": 1.536287,
     "end_time": "2022-12-22T11:35:30.571590",
     "exception": false,
     "start_time": "2022-12-22T11:35:29.035303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8dd80e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:35:30.592322Z",
     "iopub.status.busy": "2022-12-22T11:35:30.591802Z",
     "iopub.status.idle": "2022-12-22T11:35:30.602069Z",
     "shell.execute_reply": "2022-12-22T11:35:30.600750Z"
    },
    "papermill": {
     "duration": 0.023111,
     "end_time": "2022-12-22T11:35:30.604900",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.581789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory of the data\n",
    "DATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULT_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULT_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_TARGETS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\"\n",
    "FP_MULT_TRAIN_TARGETS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\"\n",
    "FP_MULT_TEST_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TEST_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\"\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "FP_EVALUATION_IDS_parquet = \"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\"\n",
    "\n",
    "multi_ome_only_file = '../input/nb2multiome/multiome_only.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9806c",
   "metadata": {
    "papermill": {
     "duration": 0.00837,
     "end_time": "2022-12-22T11:35:30.622214",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.613844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Part: Predicting protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce24d9",
   "metadata": {
    "papermill": {
     "duration": 0.00766,
     "end_time": "2022-12-22T11:35:30.638582",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.630922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the CITEseq portion begins\n",
    "\n",
    "\n",
    "Code from pourchot: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae28ba0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:35:30.657298Z",
     "iopub.status.busy": "2022-12-22T11:35:30.656229Z",
     "iopub.status.idle": "2022-12-22T11:35:30.662034Z",
     "shell.execute_reply": "2022-12-22T11:35:30.660799Z"
    },
    "papermill": {
     "duration": 0.018025,
     "end_time": "2022-12-22T11:35:30.664772",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.646747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_ncount = 128 # amount of dimensions to keep for SVD later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897053e1",
   "metadata": {
    "papermill": {
     "duration": 0.008311,
     "end_time": "2022-12-22T11:35:30.682044",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.673733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b55755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:35:30.700030Z",
     "iopub.status.busy": "2022-12-22T11:35:30.699581Z",
     "iopub.status.idle": "2022-12-22T11:37:11.532131Z",
     "shell.execute_reply": "2022-12-22T11:37:11.530599Z"
    },
    "papermill": {
     "duration": 100.845416,
     "end_time": "2022-12-22T11:37:11.535605",
     "exception": false,
     "start_time": "2022-12-22T11:35:30.690189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "\n",
    "# Load test inputs\n",
    "X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dbe20f",
   "metadata": {
    "papermill": {
     "duration": 0.007657,
     "end_time": "2022-12-22T11:37:11.551891",
     "exception": false,
     "start_time": "2022-12-22T11:37:11.544234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Constant columns (a.k.a. columns that have the same value in all rows) are useless for machine learning. Just like if you are told to differentiate between apples and oranges, and there is a column which indicates whether apples and oranges are fruits and vegetables, both the apples and oranges will be \"fruit,\" which informs you nothing about the difference between apples and oranges.\n",
    "\n",
    "Hence, constant columns found in the training inputs are found in order to be removed from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120dafef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:11.569399Z",
     "iopub.status.busy": "2022-12-22T11:37:11.568965Z",
     "iopub.status.idle": "2022-12-22T11:37:14.347607Z",
     "shell.execute_reply": "2022-12-22T11:37:14.346304Z"
    },
    "papermill": {
     "duration": 2.791021,
     "end_time": "2022-12-22T11:37:14.350540",
     "exception": false,
     "start_time": "2022-12-22T11:37:11.559519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant columns  1194\n"
     ]
    }
   ],
   "source": [
    "constant_cols = list(X.columns[(X == 0).all(axis=0).values]) +\\\n",
    "                list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "print('constant columns ',len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9858b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:14.368709Z",
     "iopub.status.busy": "2022-12-22T11:37:14.367474Z",
     "iopub.status.idle": "2022-12-22T11:37:19.032065Z",
     "shell.execute_reply": "2022-12-22T11:37:19.030335Z"
    },
    "papermill": {
     "duration": 4.677027,
     "end_time": "2022-12-22T11:37:19.035410",
     "exception": false,
     "start_time": "2022-12-22T11:37:14.358383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the constant columns from the training data\n",
    "X = X.drop(columns = constant_cols)\n",
    "Xt = X_test.drop(columns = constant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639fcac",
   "metadata": {
    "papermill": {
     "duration": 0.008056,
     "end_time": "2022-12-22T11:37:19.053074",
     "exception": false,
     "start_time": "2022-12-22T11:37:19.045018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The \"important columns\" are columns that appear as training targets. Hence, it is considered important to keep them in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4eff59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:19.074292Z",
     "iopub.status.busy": "2022-12-22T11:37:19.073840Z",
     "iopub.status.idle": "2022-12-22T11:37:19.550112Z",
     "shell.execute_reply": "2022-12-22T11:37:19.548717Z"
    },
    "papermill": {
     "duration": 0.490966,
     "end_time": "2022-12-22T11:37:19.552789",
     "exception": false,
     "start_time": "2022-12-22T11:37:19.061823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important columns  144\n"
     ]
    }
   ],
   "source": [
    "important_cols = []\n",
    "for y_col in Y.columns:\n",
    "    important_cols += [x_col for x_col in X.columns if y_col in x_col]\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030f3ca",
   "metadata": {
    "papermill": {
     "duration": 0.007578,
     "end_time": "2022-12-22T11:37:19.568402",
     "exception": false,
     "start_time": "2022-12-22T11:37:19.560824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before this point, the training and testing data has been loaded in order to determine the constant columns. The training and testing data will be loaded now as sparse matrices with the constant columns removed and the important columns kept. The purpose of sparse matrices is to efficiently store data with lots of zeros and also speed up the machine learning processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9512ea12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:19.590505Z",
     "iopub.status.busy": "2022-12-22T11:37:19.590003Z",
     "iopub.status.idle": "2022-12-22T11:37:19.641296Z",
     "shell.execute_reply": "2022-12-22T11:37:19.639911Z"
    },
    "papermill": {
     "duration": 0.067359,
     "end_time": "2022-12-22T11:37:19.644260",
     "exception": false,
     "start_time": "2022-12-22T11:37:19.576901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410_A1BG</th>\n",
       "      <th>ENSG00000268895_A1BG-AS1</th>\n",
       "      <th>ENSG00000175899_A2M</th>\n",
       "      <th>ENSG00000245105_A2M-AS1</th>\n",
       "      <th>ENSG00000128274_A4GALT</th>\n",
       "      <th>ENSG00000094914_AAAS</th>\n",
       "      <th>ENSG00000081760_AACS</th>\n",
       "      <th>ENSG00000109576_AADAT</th>\n",
       "      <th>ENSG00000103591_AAGAB</th>\n",
       "      <th>ENSG00000115977_AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000153975_ZUP1</th>\n",
       "      <th>ENSG00000086827_ZW10</th>\n",
       "      <th>ENSG00000174442_ZWILCH</th>\n",
       "      <th>ENSG00000122952_ZWINT</th>\n",
       "      <th>ENSG00000198205_ZXDA</th>\n",
       "      <th>ENSG00000198455_ZXDB</th>\n",
       "      <th>ENSG00000070476_ZXDC</th>\n",
       "      <th>ENSG00000162378_ZYG11B</th>\n",
       "      <th>ENSG00000159840_ZYX</th>\n",
       "      <th>ENSG00000074755_ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.090185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>4.529743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.513782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>5.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51861</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>3.518610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410_A1BG  ENSG00000268895_A1BG-AS1  \\\n",
       "cell_id                                                        \n",
       "45006fe3e4c8                   0.0                       0.0   \n",
       "d02759a80ba2                   0.0                       0.0   \n",
       "c016c6b0efa5                   0.0                       0.0   \n",
       "ba7f733a4f75                   0.0                       0.0   \n",
       "fbcf2443ffb2                   0.0                       0.0   \n",
       "\n",
       "gene_id       ENSG00000175899_A2M  ENSG00000245105_A2M-AS1  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                  0.0                      0.0   \n",
       "d02759a80ba2                  0.0                      0.0   \n",
       "c016c6b0efa5                  0.0                      0.0   \n",
       "ba7f733a4f75                  0.0                      0.0   \n",
       "fbcf2443ffb2                  0.0                      0.0   \n",
       "\n",
       "gene_id       ENSG00000128274_A4GALT  ENSG00000094914_AAAS  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                0.000000              0.000000   \n",
       "d02759a80ba2                0.000000              0.000000   \n",
       "c016c6b0efa5                3.847321              0.000000   \n",
       "ba7f733a4f75                0.000000              3.436846   \n",
       "fbcf2443ffb2                0.000000              0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760_AACS  ENSG00000109576_AADAT  \\\n",
       "cell_id                                                     \n",
       "45006fe3e4c8              0.000000               0.000000   \n",
       "d02759a80ba2              0.000000               0.000000   \n",
       "c016c6b0efa5              3.847321               3.847321   \n",
       "ba7f733a4f75              3.436846               0.000000   \n",
       "fbcf2443ffb2              4.196826               0.000000   \n",
       "\n",
       "gene_id       ENSG00000103591_AAGAB  ENSG00000115977_AAK1  ...  \\\n",
       "cell_id                                                    ...   \n",
       "45006fe3e4c8                    0.0              0.000000  ...   \n",
       "d02759a80ba2                    0.0              4.039545  ...   \n",
       "c016c6b0efa5                    0.0              0.000000  ...   \n",
       "ba7f733a4f75                    0.0              4.513782  ...   \n",
       "fbcf2443ffb2                    0.0              0.000000  ...   \n",
       "\n",
       "gene_id       ENSG00000153975_ZUP1  ENSG00000086827_ZW10  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8              0.000000              0.000000   \n",
       "d02759a80ba2              0.000000              0.000000   \n",
       "c016c6b0efa5              0.000000              0.000000   \n",
       "ba7f733a4f75              3.436846              0.000000   \n",
       "fbcf2443ffb2              0.000000              4.196826   \n",
       "\n",
       "gene_id       ENSG00000174442_ZWILCH  ENSG00000122952_ZWINT  \\\n",
       "cell_id                                                       \n",
       "45006fe3e4c8                0.000000               0.000000   \n",
       "d02759a80ba2                0.000000               4.039545   \n",
       "c016c6b0efa5                3.847321               4.529743   \n",
       "ba7f733a4f75                4.113780               5.020215   \n",
       "fbcf2443ffb2                4.196826               4.196826   \n",
       "\n",
       "gene_id       ENSG00000198205_ZXDA  ENSG00000198455_ZXDB  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8                   0.0                   0.0   \n",
       "d02759a80ba2                   0.0                   0.0   \n",
       "c016c6b0efa5                   0.0                   0.0   \n",
       "ba7f733a4f75                   0.0                   0.0   \n",
       "fbcf2443ffb2                   0.0                   0.0   \n",
       "\n",
       "gene_id       ENSG00000070476_ZXDC  ENSG00000162378_ZYG11B  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8               0.00000                0.000000   \n",
       "d02759a80ba2               0.00000                0.000000   \n",
       "c016c6b0efa5               0.00000                3.847321   \n",
       "ba7f733a4f75               0.00000                3.436846   \n",
       "fbcf2443ffb2               3.51861                4.196826   \n",
       "\n",
       "gene_id       ENSG00000159840_ZYX  ENSG00000074755_ZZEF1  \n",
       "cell_id                                                   \n",
       "45006fe3e4c8             4.090185                    0.0  \n",
       "d02759a80ba2             0.000000                    0.0  \n",
       "c016c6b0efa5             3.847321                    0.0  \n",
       "ba7f733a4f75             4.113780                    0.0  \n",
       "fbcf2443ffb2             3.518610                    0.0  \n",
       "\n",
       "[5 rows x 20856 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, taking a look at X shows there are a LOT of zeros:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1122a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:19.664755Z",
     "iopub.status.busy": "2022-12-22T11:37:19.664299Z",
     "iopub.status.idle": "2022-12-22T11:37:20.284669Z",
     "shell.execute_reply": "2022-12-22T11:37:20.283219Z"
    },
    "papermill": {
     "duration": 0.634598,
     "end_time": "2022-12-22T11:37:20.287910",
     "exception": false,
     "start_time": "2022-12-22T11:37:19.653312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119651, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first delete the X, X_test, Xt, and Y to save space\n",
    "del X\n",
    "del X_test\n",
    "del Xt\n",
    "del Y\n",
    "\n",
    "# load in the metadata since it'll be modified as well in the next cell\n",
    "# (Since X and Y are modified, it is convenient to modify the metadata to match\n",
    "# at the same time)\n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"] # focus on citeseq right now\n",
    "metadata_df.shape # show the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63573449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:37:20.307924Z",
     "iopub.status.busy": "2022-12-22T11:37:20.307421Z",
     "iopub.status.idle": "2022-12-22T11:40:35.438675Z",
     "shell.execute_reply": "2022-12-22T11:40:35.437180Z"
    },
    "papermill": {
     "duration": 195.151547,
     "end_time": "2022-12-22T11:40:35.448853",
     "exception": false,
     "start_time": "2022-12-22T11:37:20.297306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (70988, 20856) 5.515 GByte\n",
      "Original Xt shape: (48663, 20856) 3.781 GByte\n",
      "CPU times: user 2min 18s, sys: 19.6 s, total: 2min 38s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 17s\n",
    "\n",
    "# Now, the data will be converted into sparse matrices\n",
    "# (See MSCI CITEseq Keras Quickstart by AMBROSM)\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "print(f\"Original X shape: {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "X = scipy.sparse.csr_matrix(X.values)\n",
    "gc.collect()\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "print(f\"Original Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "Xt = scipy.sparse.csr_matrix(Xt.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c20f54",
   "metadata": {
    "papermill": {
     "duration": 0.009037,
     "end_time": "2022-12-22T11:40:35.466672",
     "exception": false,
     "start_time": "2022-12-22T11:40:35.457635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform SVD\n",
    "Now perform SVD in order to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23801ebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:40:35.487277Z",
     "iopub.status.busy": "2022-12-22T11:40:35.486330Z",
     "iopub.status.idle": "2022-12-22T11:49:28.867690Z",
     "shell.execute_reply": "2022-12-22T11:49:28.864620Z"
    },
    "papermill": {
     "duration": 533.403009,
     "end_time": "2022-12-22T11:49:28.878501",
     "exception": false,
     "start_time": "2022-12-22T11:40:35.475492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (119651, 20856)\n",
      "Shape of both after SVD:  (119651, 128)\n",
      "Reduced X shape:  (70988, 272)   0.072 GByte\n",
      "Reduced Xt shape: (48663, 272)   0.049 GByte\n",
      "CPU times: user 8min 53s, sys: 8.81 s, total: 9min 2s\n",
      "Wall time: 8min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5-6 minutes\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "assert both.shape[0] == 119651\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n",
    "svd = TruncatedSVD(n_components=svd_ncount, random_state=1) # 512 is possible\n",
    "both = svd.fit_transform(both)\n",
    "print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:70988]\n",
    "Xt = both[70988:]\n",
    "del both\n",
    "X = np.hstack([X, X0])\n",
    "Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea4bbc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:28.903151Z",
     "iopub.status.busy": "2022-12-22T11:49:28.902568Z",
     "iopub.status.idle": "2022-12-22T11:49:28.911620Z",
     "shell.execute_reply": "2022-12-22T11:49:28.910046Z"
    },
    "papermill": {
     "duration": 0.026756,
     "end_time": "2022-12-22T11:49:28.915650",
     "exception": false,
     "start_time": "2022-12-22T11:49:28.888894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:\n",
      "0.14895947\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\")\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928cc7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:28.939032Z",
     "iopub.status.busy": "2022-12-22T11:49:28.938559Z",
     "iopub.status.idle": "2022-12-22T11:49:29.761821Z",
     "shell.execute_reply": "2022-12-22T11:49:29.759896Z"
    },
    "papermill": {
     "duration": 0.839986,
     "end_time": "2022-12-22T11:49:29.766035",
     "exception": false,
     "start_time": "2022-12-22T11:49:28.926049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (70988, 140)   0.037 GByte\n"
     ]
    }
   ],
   "source": [
    "# Read Y\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "y_columns = list(Y.columns)\n",
    "Y = Y.values\n",
    "\n",
    "# Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# and negative_correlation_loss depends on it\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d50d168",
   "metadata": {
    "papermill": {
     "duration": 0.008888,
     "end_time": "2022-12-22T11:49:29.784659",
     "exception": false,
     "start_time": "2022-12-22T11:49:29.775771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CITEseq learning model\n",
    "\n",
    "From: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aedfa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:29.804980Z",
     "iopub.status.busy": "2022-12-22T11:49:29.804521Z",
     "iopub.status.idle": "2022-12-22T11:49:38.221481Z",
     "shell.execute_reply": "2022-12-22T11:49:38.219546Z"
    },
    "papermill": {
     "duration": 8.431364,
     "end_time": "2022-12-22T11:49:38.225190",
     "exception": false,
     "start_time": "2022-12-22T11:49:29.793826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446bc18",
   "metadata": {
    "papermill": {
     "duration": 0.010052,
     "end_time": "2022-12-22T11:49:38.244641",
     "exception": false,
     "start_time": "2022-12-22T11:49:38.234589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metric and loss function from MSCI CITEseq Keras Quickstart by AMBROSM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4aeef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:38.267092Z",
     "iopub.status.busy": "2022-12-22T11:49:38.265620Z",
     "iopub.status.idle": "2022-12-22T11:49:38.278039Z",
     "shell.execute_reply": "2022-12-22T11:49:38.276864Z"
    },
    "papermill": {
     "duration": 0.027172,
     "end_time": "2022-12-22T11:49:38.281115",
     "exception": false,
     "start_time": "2022-12-22T11:49:38.253943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "020883c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:38.303885Z",
     "iopub.status.busy": "2022-12-22T11:49:38.303036Z",
     "iopub.status.idle": "2022-12-22T11:49:38.313836Z",
     "shell.execute_reply": "2022-12-22T11:49:38.312487Z"
    },
    "papermill": {
     "duration": 0.025206,
     "end_time": "2022-12-22T11:49:38.316801",
     "exception": false,
     "start_time": "2022-12-22T11:49:38.291595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(256, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1) \n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2)\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a999747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T11:49:38.340752Z",
     "iopub.status.busy": "2022-12-22T11:49:38.339983Z",
     "iopub.status.idle": "2022-12-22T12:03:06.138317Z",
     "shell.execute_reply": "2022-12-22T12:03:06.136680Z"
    },
    "papermill": {
     "duration": 808.303977,
     "end_time": "2022-12-22T12:03:06.631951",
     "exception": false,
     "start_time": "2022-12-22T11:49:38.327974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 11:49:38.715657: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-22 11:49:39.122888: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 7s 57ms/step - loss: -0.8213 - negative_correlation_loss: -0.8381 - val_loss: -0.8531 - val_negative_correlation_loss: -0.8661\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8740 - negative_correlation_loss: -0.8849 - val_loss: -0.8682 - val_negative_correlation_loss: -0.8768\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8853 - negative_correlation_loss: -0.8930 - val_loss: -0.8721 - val_negative_correlation_loss: -0.8785\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.8899 - negative_correlation_loss: -0.8962 - val_loss: -0.8787 - val_negative_correlation_loss: -0.8844\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: -0.8930 - negative_correlation_loss: -0.8986 - val_loss: -0.8790 - val_negative_correlation_loss: -0.8841\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 5s 55ms/step - loss: -0.8947 - negative_correlation_loss: -0.8999 - val_loss: -0.8814 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: -0.8954 - negative_correlation_loss: -0.9004 - val_loss: -0.8808 - val_negative_correlation_loss: -0.8853\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 6s 68ms/step - loss: -0.8962 - negative_correlation_loss: -0.9009 - val_loss: -0.8820 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8968 - negative_correlation_loss: -0.9013 - val_loss: -0.8826 - val_negative_correlation_loss: -0.8868\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8972 - negative_correlation_loss: -0.9017 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 5s 58ms/step - loss: -0.8975 - negative_correlation_loss: -0.9019 - val_loss: -0.8825 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.8978 - negative_correlation_loss: -0.9019 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8977 - negative_correlation_loss: -0.9020 - val_loss: -0.8823 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8980 - negative_correlation_loss: -0.9022 - val_loss: -0.8825 - val_negative_correlation_loss: -0.8864\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8986 - negative_correlation_loss: -0.9025 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 5s 53ms/step - loss: -0.8986 - negative_correlation_loss: -0.9026 - val_loss: -0.8809 - val_negative_correlation_loss: -0.8845\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: -0.8988 - negative_correlation_loss: -0.9028 - val_loss: -0.8798 - val_negative_correlation_loss: -0.8834\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 6s 69ms/step - loss: -0.8988 - negative_correlation_loss: -0.9027 - val_loss: -0.8828 - val_negative_correlation_loss: -0.8865\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: -0.8990 - negative_correlation_loss: -0.9028 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8875\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 6s 65ms/step - loss: -0.8993 - negative_correlation_loss: -0.9031 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 6s 62ms/step - loss: -0.8995 - negative_correlation_loss: -0.9033 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 7s 74ms/step - loss: -0.8994 - negative_correlation_loss: -0.9031 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8997 - negative_correlation_loss: -0.9034 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8996 - negative_correlation_loss: -0.9033 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8875\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8995 - negative_correlation_loss: -0.9033 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8882\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9000 - negative_correlation_loss: -0.9036 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 5s 53ms/step - loss: -0.9001 - negative_correlation_loss: -0.9037 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9000 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8892\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: -0.9001 - negative_correlation_loss: -0.9038 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8999 - negative_correlation_loss: -0.9036 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9002 - negative_correlation_loss: -0.9038 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9002 - negative_correlation_loss: -0.9038 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9000 - negative_correlation_loss: -0.9037 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8867\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9002 - negative_correlation_loss: -0.9037 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9000 - negative_correlation_loss: -0.9037 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: -0.9002 - negative_correlation_loss: -0.9037 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8880\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9005 - negative_correlation_loss: -0.9040 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8873\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9007 - negative_correlation_loss: -0.9043 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9006 - negative_correlation_loss: -0.9041 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9008 - negative_correlation_loss: -0.9042 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9006 - negative_correlation_loss: -0.9042 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9008 - negative_correlation_loss: -0.9042 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 5s 60ms/step - loss: -0.9003 - negative_correlation_loss: -0.9039 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9006 - negative_correlation_loss: -0.9040 - val_loss: -0.8835 - val_negative_correlation_loss: -0.8867\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9009 - negative_correlation_loss: -0.9042 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9012 - negative_correlation_loss: -0.9045 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9008 - negative_correlation_loss: -0.9041 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9010 - negative_correlation_loss: -0.9043 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8875\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 5s 59ms/step - loss: -0.9013 - negative_correlation_loss: -0.9046 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9014 - negative_correlation_loss: -0.9046 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 11:53:50.946210: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Fold 0, correlation =  0.89009\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 54ms/step - loss: -0.7951 - negative_correlation_loss: -0.8126 - val_loss: -0.8408 - val_negative_correlation_loss: -0.8559\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8465 - negative_correlation_loss: -0.8582 - val_loss: -0.8564 - val_negative_correlation_loss: -0.8662\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8669 - negative_correlation_loss: -0.8756 - val_loss: -0.8729 - val_negative_correlation_loss: -0.8804\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8788 - negative_correlation_loss: -0.8857 - val_loss: -0.8783 - val_negative_correlation_loss: -0.8846\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8844 - negative_correlation_loss: -0.8903 - val_loss: -0.8826 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8881 - negative_correlation_loss: -0.8935 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8903 - negative_correlation_loss: -0.8956 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8912\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8916 - negative_correlation_loss: -0.8967 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8914\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8926 - negative_correlation_loss: -0.8974 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8910\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8933 - negative_correlation_loss: -0.8980 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8922\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8935 - negative_correlation_loss: -0.8981 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8923\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8939 - negative_correlation_loss: -0.8985 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8926\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8944 - negative_correlation_loss: -0.8988 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8944 - negative_correlation_loss: -0.8988 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8928\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8947 - negative_correlation_loss: -0.8990 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8948 - negative_correlation_loss: -0.8991 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8950 - negative_correlation_loss: -0.8993 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8952 - negative_correlation_loss: -0.8995 - val_loss: -0.8894 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8952 - negative_correlation_loss: -0.8995 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8934\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8953 - negative_correlation_loss: -0.8995 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8925\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8953 - negative_correlation_loss: -0.8996 - val_loss: -0.8883 - val_negative_correlation_loss: -0.8925\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8954 - negative_correlation_loss: -0.8997 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8918\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8958 - negative_correlation_loss: -0.8999 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8932\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8959 - negative_correlation_loss: -0.8999 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8961 - negative_correlation_loss: -0.9000 - val_loss: -0.8904 - val_negative_correlation_loss: -0.8943\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8961 - negative_correlation_loss: -0.9001 - val_loss: -0.8897 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8961 - negative_correlation_loss: -0.9001 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8960 - negative_correlation_loss: -0.9000 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8924\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8960 - negative_correlation_loss: -0.9000 - val_loss: -0.8888 - val_negative_correlation_loss: -0.8927\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8966 - negative_correlation_loss: -0.9005 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8947\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8967 - negative_correlation_loss: -0.9005 - val_loss: -0.8900 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8965 - negative_correlation_loss: -0.9003 - val_loss: -0.8894 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8966 - negative_correlation_loss: -0.9004 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8967 - negative_correlation_loss: -0.9005 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8947\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8970 - negative_correlation_loss: -0.9007 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8970 - negative_correlation_loss: -0.9006 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8942\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: -0.8970 - negative_correlation_loss: -0.9007 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8971 - negative_correlation_loss: -0.9008 - val_loss: -0.8898 - val_negative_correlation_loss: -0.8934\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8974 - negative_correlation_loss: -0.9010 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8975 - negative_correlation_loss: -0.9010 - val_loss: -0.8902 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8975 - negative_correlation_loss: -0.9010 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8927\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8975 - negative_correlation_loss: -0.9011 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8975 - negative_correlation_loss: -0.9010 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8938\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: -0.8978 - negative_correlation_loss: -0.9012 - val_loss: -0.8919 - val_negative_correlation_loss: -0.8953\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8980 - negative_correlation_loss: -0.9014 - val_loss: -0.8915 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8979 - negative_correlation_loss: -0.9013 - val_loss: -0.8902 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8979 - negative_correlation_loss: -0.9013 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8943\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8979 - negative_correlation_loss: -0.9014 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8941\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8982 - negative_correlation_loss: -0.9016 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8943\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8982 - negative_correlation_loss: -0.9015 - val_loss: -0.8920 - val_negative_correlation_loss: -0.8953\n",
      "model saved\n",
      "Fold 1, correlation =  0.89528\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 6s 52ms/step - loss: -0.8036 - negative_correlation_loss: -0.8201 - val_loss: -0.8433 - val_negative_correlation_loss: -0.8559\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8643 - negative_correlation_loss: -0.8747 - val_loss: -0.8669 - val_negative_correlation_loss: -0.8753\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8785 - negative_correlation_loss: -0.8859 - val_loss: -0.8747 - val_negative_correlation_loss: -0.8811\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8858 - negative_correlation_loss: -0.8918 - val_loss: -0.8793 - val_negative_correlation_loss: -0.8848\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8891 - negative_correlation_loss: -0.8946 - val_loss: -0.8820 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8911 - negative_correlation_loss: -0.8962 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 5s 56ms/step - loss: -0.8921 - negative_correlation_loss: -0.8970 - val_loss: -0.8834 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8931 - negative_correlation_loss: -0.8977 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8932 - negative_correlation_loss: -0.8977 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 6s 62ms/step - loss: -0.8938 - negative_correlation_loss: -0.8982 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8943 - negative_correlation_loss: -0.8985 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8944 - negative_correlation_loss: -0.8987 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 5s 57ms/step - loss: -0.8947 - negative_correlation_loss: -0.8989 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8948 - negative_correlation_loss: -0.8989 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8950 - negative_correlation_loss: -0.8991 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8950 - negative_correlation_loss: -0.8990 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8879\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8954 - negative_correlation_loss: -0.8994 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8955 - negative_correlation_loss: -0.8994 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 6s 62ms/step - loss: -0.8957 - negative_correlation_loss: -0.8996 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8957 - negative_correlation_loss: -0.8996 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8900\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8959 - negative_correlation_loss: -0.8998 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8899\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8963 - negative_correlation_loss: -0.9000 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8965 - negative_correlation_loss: -0.9002 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8965 - negative_correlation_loss: -0.9003 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8964 - negative_correlation_loss: -0.9001 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8895\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8966 - negative_correlation_loss: -0.9002 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8965 - negative_correlation_loss: -0.9002 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8895\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8969 - negative_correlation_loss: -0.9004 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8911\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8969 - negative_correlation_loss: -0.9004 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8970 - negative_correlation_loss: -0.9005 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8972 - negative_correlation_loss: -0.9006 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8901\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 5s 57ms/step - loss: -0.8971 - negative_correlation_loss: -0.9006 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8902\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8973 - negative_correlation_loss: -0.9007 - val_loss: -0.8881 - val_negative_correlation_loss: -0.8914\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8972 - negative_correlation_loss: -0.9007 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8973 - negative_correlation_loss: -0.9008 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8917\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8974 - negative_correlation_loss: -0.9009 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8912\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8974 - negative_correlation_loss: -0.9009 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8974 - negative_correlation_loss: -0.9008 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8911\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8975 - negative_correlation_loss: -0.9009 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8909\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8977 - negative_correlation_loss: -0.9011 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8978 - negative_correlation_loss: -0.9011 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8978 - negative_correlation_loss: -0.9010 - val_loss: -0.8883 - val_negative_correlation_loss: -0.8914\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8979 - negative_correlation_loss: -0.9012 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8917\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8981 - negative_correlation_loss: -0.9014 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 5s 57ms/step - loss: -0.8981 - negative_correlation_loss: -0.9014 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8983 - negative_correlation_loss: -0.9015 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8917\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8982 - negative_correlation_loss: -0.9013 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8982 - negative_correlation_loss: -0.9014 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8983 - negative_correlation_loss: -0.9015 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8915\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8984 - negative_correlation_loss: -0.9016 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8907\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "model saved\n",
      "Fold 2, correlation =  0.89174\n",
      "\u001b[32m\u001b[1mMean corr = 0.89237\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89236\u001b[0m\n",
      "CPU times: user 32min 37s, sys: 1min 8s, total: 33min 45s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 13 min 44 s\n",
    "VERBOSE = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 50 \n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 40, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"min\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [\n",
    "                    lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b222a88",
   "metadata": {
    "papermill": {
     "duration": 0.56537,
     "end_time": "2022-12-22T12:03:07.691639",
     "exception": false,
     "start_time": "2022-12-22T12:03:07.126269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57c92e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:03:08.670032Z",
     "iopub.status.busy": "2022-12-22T12:03:08.669241Z",
     "iopub.status.idle": "2022-12-22T12:03:23.219245Z",
     "shell.execute_reply": "2022-12-22T12:03:23.217623Z"
    },
    "papermill": {
     "duration": 15.044113,
     "end_time": "2022-12-22T12:03:23.221983",
     "exception": false,
     "start_time": "2022-12-22T12:03:08.177870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "Predicting with fold 1\n",
      "Predicting with fold 2\n",
      "CPU times: user 20.7 s, sys: 2.75 s, total: 23.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Around 20 s\n",
    "\n",
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09848f96",
   "metadata": {
    "papermill": {
     "duration": 0.487799,
     "end_time": "2022-12-22T12:03:24.272207",
     "exception": false,
     "start_time": "2022-12-22T12:03:23.784408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save submission by merging with multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2324b705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:03:25.339064Z",
     "iopub.status.busy": "2022-12-22T12:03:25.338160Z",
     "iopub.status.idle": "2022-12-22T12:07:11.249057Z",
     "shell.execute_reply": "2022-12-22T12:07:11.247545Z"
    },
    "papermill": {
     "duration": 226.999489,
     "end_time": "2022-12-22T12:07:11.766242",
     "exception": false,
     "start_time": "2022-12-22T12:03:24.766753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0          -302.979309\n",
       "1          -289.225708\n",
       "2          -253.082932\n",
       "3           182.063492\n",
       "4           310.215454\n",
       "               ...    \n",
       "65744175      9.453125\n",
       "65744176      0.062561\n",
       "65744177      0.077026\n",
       "65744178      1.852539\n",
       "65744179      8.085938\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 14.5 s, total: 3min 31s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 41s\n",
    "\n",
    "# Merge with multiome\n",
    "submission = pd.read_csv(multi_ome_only_file,index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_full_m128_m128.csv')\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1931.000701,
   "end_time": "2022-12-22T12:07:15.755191",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-22T11:35:04.754490",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
