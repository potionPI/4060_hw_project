{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c23914f",
   "metadata": {
    "papermill": {
     "duration": 0.008621,
     "end_time": "2022-12-22T12:16:05.759515",
     "exception": false,
     "start_time": "2022-12-22T12:16:05.750894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because the datasets are SO large (especially the Multiome dataset), instead of running both parts of the project in one notebook (and risk Kaggle running out of storage space then resetting all progress), it is more convenient to separate the multiome and citeseq parts of the project, then later merge the predicted outputs from the two parts together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38780f4a",
   "metadata": {
    "papermill": {
     "duration": 0.007073,
     "end_time": "2022-12-22T12:16:05.774192",
     "exception": false,
     "start_time": "2022-12-22T12:16:05.767119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook concerns itself with the CITEseq portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9c060",
   "metadata": {
    "papermill": {
     "duration": 0.007024,
     "end_time": "2022-12-22T12:16:05.788508",
     "exception": false,
     "start_time": "2022-12-22T12:16:05.781484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First, all the basic imports and file names which may or may not be used is loaded in essentially as a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d97028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:16:05.805724Z",
     "iopub.status.busy": "2022-12-22T12:16:05.804909Z",
     "iopub.status.idle": "2022-12-22T12:16:19.023098Z",
     "shell.execute_reply": "2022-12-22T12:16:19.021261Z"
    },
    "papermill": {
     "duration": 13.23039,
     "end_time": "2022-12-22T12:16:19.026276",
     "exception": false,
     "start_time": "2022-12-22T12:16:05.795886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/conda/lib/python3.7/site-packages (3.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from tables) (1.21.6)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tables) (21.3)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables) (2.8.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tables) (3.0.9)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea5343f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-22T12:16:19.046246Z",
     "iopub.status.busy": "2022-12-22T12:16:19.045514Z",
     "iopub.status.idle": "2022-12-22T12:16:20.393282Z",
     "shell.execute_reply": "2022-12-22T12:16:20.391401Z"
    },
    "papermill": {
     "duration": 1.361013,
     "end_time": "2022-12-22T12:16:20.396740",
     "exception": false,
     "start_time": "2022-12-22T12:16:19.035727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2143b05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:16:20.424180Z",
     "iopub.status.busy": "2022-12-22T12:16:20.423636Z",
     "iopub.status.idle": "2022-12-22T12:16:20.435997Z",
     "shell.execute_reply": "2022-12-22T12:16:20.434588Z"
    },
    "papermill": {
     "duration": 0.026835,
     "end_time": "2022-12-22T12:16:20.438540",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.411705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory of the data\n",
    "DATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULT_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULT_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_TARGETS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\"\n",
    "FP_MULT_TRAIN_TARGETS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\"\n",
    "FP_MULT_TEST_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TEST_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\"\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "FP_EVALUATION_IDS_parquet = \"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\"\n",
    "\n",
    "multi_ome_only_file = '../input/nb2multiome/multiome_only.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35a852",
   "metadata": {
    "papermill": {
     "duration": 0.012749,
     "end_time": "2022-12-22T12:16:20.460210",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.447461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Part: Predicting protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50889e",
   "metadata": {
    "papermill": {
     "duration": 0.007369,
     "end_time": "2022-12-22T12:16:20.475648",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.468279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the CITEseq portion begins\n",
    "\n",
    "\n",
    "Code from pourchot: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ca859e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:16:20.492680Z",
     "iopub.status.busy": "2022-12-22T12:16:20.492182Z",
     "iopub.status.idle": "2022-12-22T12:16:20.497486Z",
     "shell.execute_reply": "2022-12-22T12:16:20.496335Z"
    },
    "papermill": {
     "duration": 0.016553,
     "end_time": "2022-12-22T12:16:20.499812",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.483259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_ncount = 64 # amount of dimensions to keep for SVD later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5659a1",
   "metadata": {
    "papermill": {
     "duration": 0.007799,
     "end_time": "2022-12-22T12:16:20.515675",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.507876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7571a6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:16:20.533452Z",
     "iopub.status.busy": "2022-12-22T12:16:20.533008Z",
     "iopub.status.idle": "2022-12-22T12:17:51.529365Z",
     "shell.execute_reply": "2022-12-22T12:17:51.528239Z"
    },
    "papermill": {
     "duration": 91.009029,
     "end_time": "2022-12-22T12:17:51.532474",
     "exception": false,
     "start_time": "2022-12-22T12:16:20.523445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "\n",
    "# Load test inputs\n",
    "X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff82e4",
   "metadata": {
    "papermill": {
     "duration": 0.007478,
     "end_time": "2022-12-22T12:17:51.547944",
     "exception": false,
     "start_time": "2022-12-22T12:17:51.540466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Constant columns (a.k.a. columns that have the same value in all rows) are useless for machine learning. Just like if you are told to differentiate between apples and oranges, and there is a column which indicates whether apples and oranges are fruits and vegetables, both the apples and oranges will be \"fruit,\" which informs you nothing about the difference between apples and oranges.\n",
    "\n",
    "Hence, constant columns found in the training inputs are found in order to be removed from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed0f277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:51.565305Z",
     "iopub.status.busy": "2022-12-22T12:17:51.564911Z",
     "iopub.status.idle": "2022-12-22T12:17:54.151279Z",
     "shell.execute_reply": "2022-12-22T12:17:54.150028Z"
    },
    "papermill": {
     "duration": 2.598026,
     "end_time": "2022-12-22T12:17:54.153823",
     "exception": false,
     "start_time": "2022-12-22T12:17:51.555797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant columns  1194\n"
     ]
    }
   ],
   "source": [
    "constant_cols = list(X.columns[(X == 0).all(axis=0).values]) +\\\n",
    "                list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "print('constant columns ',len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ce11a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:54.170901Z",
     "iopub.status.busy": "2022-12-22T12:17:54.170505Z",
     "iopub.status.idle": "2022-12-22T12:17:57.336438Z",
     "shell.execute_reply": "2022-12-22T12:17:57.335385Z"
    },
    "papermill": {
     "duration": 3.177731,
     "end_time": "2022-12-22T12:17:57.339377",
     "exception": false,
     "start_time": "2022-12-22T12:17:54.161646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the constant columns from the training data\n",
    "X = X.drop(columns = constant_cols)\n",
    "Xt = X_test.drop(columns = constant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497c291",
   "metadata": {
    "papermill": {
     "duration": 0.008083,
     "end_time": "2022-12-22T12:17:57.356285",
     "exception": false,
     "start_time": "2022-12-22T12:17:57.348202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The \"important columns\" are columns that appear as training targets. Hence, it is considered important to keep them in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842a6aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:57.373379Z",
     "iopub.status.busy": "2022-12-22T12:17:57.372974Z",
     "iopub.status.idle": "2022-12-22T12:17:57.843160Z",
     "shell.execute_reply": "2022-12-22T12:17:57.841604Z"
    },
    "papermill": {
     "duration": 0.481794,
     "end_time": "2022-12-22T12:17:57.845830",
     "exception": false,
     "start_time": "2022-12-22T12:17:57.364036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important columns  144\n"
     ]
    }
   ],
   "source": [
    "important_cols = []\n",
    "for y_col in Y.columns:\n",
    "    important_cols += [x_col for x_col in X.columns if y_col in x_col]\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c946a",
   "metadata": {
    "papermill": {
     "duration": 0.007304,
     "end_time": "2022-12-22T12:17:57.861049",
     "exception": false,
     "start_time": "2022-12-22T12:17:57.853745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before this point, the training and testing data has been loaded in order to determine the constant columns. The training and testing data will be loaded now as sparse matrices with the constant columns removed and the important columns kept. The purpose of sparse matrices is to efficiently store data with lots of zeros and also speed up the machine learning processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f01abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:57.878828Z",
     "iopub.status.busy": "2022-12-22T12:17:57.878404Z",
     "iopub.status.idle": "2022-12-22T12:17:57.919114Z",
     "shell.execute_reply": "2022-12-22T12:17:57.917750Z"
    },
    "papermill": {
     "duration": 0.053063,
     "end_time": "2022-12-22T12:17:57.921765",
     "exception": false,
     "start_time": "2022-12-22T12:17:57.868702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410_A1BG</th>\n",
       "      <th>ENSG00000268895_A1BG-AS1</th>\n",
       "      <th>ENSG00000175899_A2M</th>\n",
       "      <th>ENSG00000245105_A2M-AS1</th>\n",
       "      <th>ENSG00000128274_A4GALT</th>\n",
       "      <th>ENSG00000094914_AAAS</th>\n",
       "      <th>ENSG00000081760_AACS</th>\n",
       "      <th>ENSG00000109576_AADAT</th>\n",
       "      <th>ENSG00000103591_AAGAB</th>\n",
       "      <th>ENSG00000115977_AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000153975_ZUP1</th>\n",
       "      <th>ENSG00000086827_ZW10</th>\n",
       "      <th>ENSG00000174442_ZWILCH</th>\n",
       "      <th>ENSG00000122952_ZWINT</th>\n",
       "      <th>ENSG00000198205_ZXDA</th>\n",
       "      <th>ENSG00000198455_ZXDB</th>\n",
       "      <th>ENSG00000070476_ZXDC</th>\n",
       "      <th>ENSG00000162378_ZYG11B</th>\n",
       "      <th>ENSG00000159840_ZYX</th>\n",
       "      <th>ENSG00000074755_ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.090185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>4.529743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.513782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>5.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51861</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>3.518610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410_A1BG  ENSG00000268895_A1BG-AS1  \\\n",
       "cell_id                                                        \n",
       "45006fe3e4c8                   0.0                       0.0   \n",
       "d02759a80ba2                   0.0                       0.0   \n",
       "c016c6b0efa5                   0.0                       0.0   \n",
       "ba7f733a4f75                   0.0                       0.0   \n",
       "fbcf2443ffb2                   0.0                       0.0   \n",
       "\n",
       "gene_id       ENSG00000175899_A2M  ENSG00000245105_A2M-AS1  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                  0.0                      0.0   \n",
       "d02759a80ba2                  0.0                      0.0   \n",
       "c016c6b0efa5                  0.0                      0.0   \n",
       "ba7f733a4f75                  0.0                      0.0   \n",
       "fbcf2443ffb2                  0.0                      0.0   \n",
       "\n",
       "gene_id       ENSG00000128274_A4GALT  ENSG00000094914_AAAS  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                0.000000              0.000000   \n",
       "d02759a80ba2                0.000000              0.000000   \n",
       "c016c6b0efa5                3.847321              0.000000   \n",
       "ba7f733a4f75                0.000000              3.436846   \n",
       "fbcf2443ffb2                0.000000              0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760_AACS  ENSG00000109576_AADAT  \\\n",
       "cell_id                                                     \n",
       "45006fe3e4c8              0.000000               0.000000   \n",
       "d02759a80ba2              0.000000               0.000000   \n",
       "c016c6b0efa5              3.847321               3.847321   \n",
       "ba7f733a4f75              3.436846               0.000000   \n",
       "fbcf2443ffb2              4.196826               0.000000   \n",
       "\n",
       "gene_id       ENSG00000103591_AAGAB  ENSG00000115977_AAK1  ...  \\\n",
       "cell_id                                                    ...   \n",
       "45006fe3e4c8                    0.0              0.000000  ...   \n",
       "d02759a80ba2                    0.0              4.039545  ...   \n",
       "c016c6b0efa5                    0.0              0.000000  ...   \n",
       "ba7f733a4f75                    0.0              4.513782  ...   \n",
       "fbcf2443ffb2                    0.0              0.000000  ...   \n",
       "\n",
       "gene_id       ENSG00000153975_ZUP1  ENSG00000086827_ZW10  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8              0.000000              0.000000   \n",
       "d02759a80ba2              0.000000              0.000000   \n",
       "c016c6b0efa5              0.000000              0.000000   \n",
       "ba7f733a4f75              3.436846              0.000000   \n",
       "fbcf2443ffb2              0.000000              4.196826   \n",
       "\n",
       "gene_id       ENSG00000174442_ZWILCH  ENSG00000122952_ZWINT  \\\n",
       "cell_id                                                       \n",
       "45006fe3e4c8                0.000000               0.000000   \n",
       "d02759a80ba2                0.000000               4.039545   \n",
       "c016c6b0efa5                3.847321               4.529743   \n",
       "ba7f733a4f75                4.113780               5.020215   \n",
       "fbcf2443ffb2                4.196826               4.196826   \n",
       "\n",
       "gene_id       ENSG00000198205_ZXDA  ENSG00000198455_ZXDB  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8                   0.0                   0.0   \n",
       "d02759a80ba2                   0.0                   0.0   \n",
       "c016c6b0efa5                   0.0                   0.0   \n",
       "ba7f733a4f75                   0.0                   0.0   \n",
       "fbcf2443ffb2                   0.0                   0.0   \n",
       "\n",
       "gene_id       ENSG00000070476_ZXDC  ENSG00000162378_ZYG11B  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8               0.00000                0.000000   \n",
       "d02759a80ba2               0.00000                0.000000   \n",
       "c016c6b0efa5               0.00000                3.847321   \n",
       "ba7f733a4f75               0.00000                3.436846   \n",
       "fbcf2443ffb2               3.51861                4.196826   \n",
       "\n",
       "gene_id       ENSG00000159840_ZYX  ENSG00000074755_ZZEF1  \n",
       "cell_id                                                   \n",
       "45006fe3e4c8             4.090185                    0.0  \n",
       "d02759a80ba2             0.000000                    0.0  \n",
       "c016c6b0efa5             3.847321                    0.0  \n",
       "ba7f733a4f75             4.113780                    0.0  \n",
       "fbcf2443ffb2             3.518610                    0.0  \n",
       "\n",
       "[5 rows x 20856 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, taking a look at X shows there are a LOT of zeros:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab364cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:57.940419Z",
     "iopub.status.busy": "2022-12-22T12:17:57.939998Z",
     "iopub.status.idle": "2022-12-22T12:17:58.452986Z",
     "shell.execute_reply": "2022-12-22T12:17:58.451932Z"
    },
    "papermill": {
     "duration": 0.525321,
     "end_time": "2022-12-22T12:17:58.455448",
     "exception": false,
     "start_time": "2022-12-22T12:17:57.930127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119651, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first delete the X, X_test, Xt, and Y to save space\n",
    "del X\n",
    "del X_test\n",
    "del Xt\n",
    "del Y\n",
    "\n",
    "# load in the metadata since it'll be modified as well in the next cell\n",
    "# (Since X and Y are modified, it is convenient to modify the metadata to match\n",
    "# at the same time)\n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"] # focus on citeseq right now\n",
    "metadata_df.shape # show the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ae4ed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:17:58.474348Z",
     "iopub.status.busy": "2022-12-22T12:17:58.473418Z",
     "iopub.status.idle": "2022-12-22T12:20:45.040391Z",
     "shell.execute_reply": "2022-12-22T12:20:45.039097Z"
    },
    "papermill": {
     "duration": 166.579097,
     "end_time": "2022-12-22T12:20:45.043037",
     "exception": false,
     "start_time": "2022-12-22T12:17:58.463940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (70988, 20856) 5.515 GByte\n",
      "Original Xt shape: (48663, 20856) 3.781 GByte\n",
      "CPU times: user 1min 59s, sys: 12.9 s, total: 2min 12s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 17s\n",
    "\n",
    "# Now, the data will be converted into sparse matrices\n",
    "# (See MSCI CITEseq Keras Quickstart by AMBROSM)\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "print(f\"Original X shape: {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "X = scipy.sparse.csr_matrix(X.values)\n",
    "gc.collect()\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "print(f\"Original Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "Xt = scipy.sparse.csr_matrix(Xt.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a2b4b",
   "metadata": {
    "papermill": {
     "duration": 0.008277,
     "end_time": "2022-12-22T12:20:45.059907",
     "exception": false,
     "start_time": "2022-12-22T12:20:45.051630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform SVD\n",
    "Now perform SVD in order to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e959249b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:20:45.078323Z",
     "iopub.status.busy": "2022-12-22T12:20:45.077908Z",
     "iopub.status.idle": "2022-12-22T12:24:55.770786Z",
     "shell.execute_reply": "2022-12-22T12:24:55.768432Z"
    },
    "papermill": {
     "duration": 250.716565,
     "end_time": "2022-12-22T12:24:55.784857",
     "exception": false,
     "start_time": "2022-12-22T12:20:45.068292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (119651, 20856)\n",
      "Shape of both after SVD:  (119651, 64)\n",
      "Reduced X shape:  (70988, 208)   0.055 GByte\n",
      "Reduced Xt shape: (48663, 208)   0.038 GByte\n",
      "CPU times: user 4min 11s, sys: 5.78 s, total: 4min 17s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5-6 minutes\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "assert both.shape[0] == 119651\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n",
    "svd = TruncatedSVD(n_components=svd_ncount, random_state=1) # 512 is possible\n",
    "both = svd.fit_transform(both)\n",
    "print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:70988]\n",
    "Xt = both[70988:]\n",
    "del both\n",
    "X = np.hstack([X, X0])\n",
    "Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9f6c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:24:55.805482Z",
     "iopub.status.busy": "2022-12-22T12:24:55.805022Z",
     "iopub.status.idle": "2022-12-22T12:24:55.812481Z",
     "shell.execute_reply": "2022-12-22T12:24:55.811286Z"
    },
    "papermill": {
     "duration": 0.021477,
     "end_time": "2022-12-22T12:24:55.815333",
     "exception": false,
     "start_time": "2022-12-22T12:24:55.793856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:\n",
      "0.1390541\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\")\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c7896a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:24:55.834830Z",
     "iopub.status.busy": "2022-12-22T12:24:55.834398Z",
     "iopub.status.idle": "2022-12-22T12:24:56.544995Z",
     "shell.execute_reply": "2022-12-22T12:24:56.543608Z"
    },
    "papermill": {
     "duration": 0.723816,
     "end_time": "2022-12-22T12:24:56.548036",
     "exception": false,
     "start_time": "2022-12-22T12:24:55.824220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (70988, 140)   0.037 GByte\n"
     ]
    }
   ],
   "source": [
    "# Read Y\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "y_columns = list(Y.columns)\n",
    "Y = Y.values\n",
    "\n",
    "# Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# and negative_correlation_loss depends on it\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed0470",
   "metadata": {
    "papermill": {
     "duration": 0.008984,
     "end_time": "2022-12-22T12:24:56.566149",
     "exception": false,
     "start_time": "2022-12-22T12:24:56.557165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CITEseq learning model\n",
    "\n",
    "From: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce50a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:24:56.586693Z",
     "iopub.status.busy": "2022-12-22T12:24:56.585388Z",
     "iopub.status.idle": "2022-12-22T12:25:03.483428Z",
     "shell.execute_reply": "2022-12-22T12:25:03.481957Z"
    },
    "papermill": {
     "duration": 6.911906,
     "end_time": "2022-12-22T12:25:03.486916",
     "exception": false,
     "start_time": "2022-12-22T12:24:56.575010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47a08e",
   "metadata": {
    "papermill": {
     "duration": 0.008588,
     "end_time": "2022-12-22T12:25:03.504762",
     "exception": false,
     "start_time": "2022-12-22T12:25:03.496174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metric and loss function from MSCI CITEseq Keras Quickstart by AMBROSM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f9c90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:03.525310Z",
     "iopub.status.busy": "2022-12-22T12:25:03.524607Z",
     "iopub.status.idle": "2022-12-22T12:25:03.535244Z",
     "shell.execute_reply": "2022-12-22T12:25:03.533945Z"
    },
    "papermill": {
     "duration": 0.024246,
     "end_time": "2022-12-22T12:25:03.538090",
     "exception": false,
     "start_time": "2022-12-22T12:25:03.513844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ef675c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:03.558770Z",
     "iopub.status.busy": "2022-12-22T12:25:03.558118Z",
     "iopub.status.idle": "2022-12-22T12:25:03.568617Z",
     "shell.execute_reply": "2022-12-22T12:25:03.567615Z"
    },
    "papermill": {
     "duration": 0.023532,
     "end_time": "2022-12-22T12:25:03.571146",
     "exception": false,
     "start_time": "2022-12-22T12:25:03.547614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(256, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1) \n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2)\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b24dc39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:03.591148Z",
     "iopub.status.busy": "2022-12-22T12:25:03.590455Z",
     "iopub.status.idle": "2022-12-22T12:37:27.246120Z",
     "shell.execute_reply": "2022-12-22T12:37:27.244468Z"
    },
    "papermill": {
     "duration": 744.146539,
     "end_time": "2022-12-22T12:37:27.726465",
     "exception": false,
     "start_time": "2022-12-22T12:25:03.579926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:25:03.919641: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-22 12:25:04.261668: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 7s 61ms/step - loss: -0.8195 - negative_correlation_loss: -0.8361 - val_loss: -0.8522 - val_negative_correlation_loss: -0.8651\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8741 - negative_correlation_loss: -0.8850 - val_loss: -0.8690 - val_negative_correlation_loss: -0.8776\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8857 - negative_correlation_loss: -0.8931 - val_loss: -0.8727 - val_negative_correlation_loss: -0.8789\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8902 - negative_correlation_loss: -0.8963 - val_loss: -0.8778 - val_negative_correlation_loss: -0.8831\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8930 - negative_correlation_loss: -0.8984 - val_loss: -0.8799 - val_negative_correlation_loss: -0.8848\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8949 - negative_correlation_loss: -0.8998 - val_loss: -0.8808 - val_negative_correlation_loss: -0.8851\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8955 - negative_correlation_loss: -0.9001 - val_loss: -0.8797 - val_negative_correlation_loss: -0.8839\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8963 - negative_correlation_loss: -0.9007 - val_loss: -0.8820 - val_negative_correlation_loss: -0.8860\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8971 - negative_correlation_loss: -0.9013 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8875\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8976 - negative_correlation_loss: -0.9016 - val_loss: -0.8824 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8978 - negative_correlation_loss: -0.9016 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8874\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8980 - negative_correlation_loss: -0.9018 - val_loss: -0.8823 - val_negative_correlation_loss: -0.8859\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8981 - negative_correlation_loss: -0.9020 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8853\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: -0.8987 - negative_correlation_loss: -0.9022 - val_loss: -0.8843 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 5s 55ms/step - loss: -0.8987 - negative_correlation_loss: -0.9024 - val_loss: -0.8827 - val_negative_correlation_loss: -0.8860\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8795 - val_negative_correlation_loss: -0.8829\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8833 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8991 - negative_correlation_loss: -0.9026 - val_loss: -0.8836 - val_negative_correlation_loss: -0.8869\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8992 - negative_correlation_loss: -0.9028 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8995 - negative_correlation_loss: -0.9030 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: -0.8995 - negative_correlation_loss: -0.9030 - val_loss: -0.8843 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.8997 - negative_correlation_loss: -0.9031 - val_loss: -0.8838 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8996 - negative_correlation_loss: -0.9030 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8874\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8998 - negative_correlation_loss: -0.9032 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9001 - negative_correlation_loss: -0.9033 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.8999 - negative_correlation_loss: -0.9033 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.9000 - negative_correlation_loss: -0.9033 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9001 - negative_correlation_loss: -0.9035 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8893\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9003 - negative_correlation_loss: -0.9036 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9003 - negative_correlation_loss: -0.9035 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8887\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9007 - negative_correlation_loss: -0.9039 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8874\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.9010 - negative_correlation_loss: -0.9042 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9007 - negative_correlation_loss: -0.9039 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9009 - negative_correlation_loss: -0.9040 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8895\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9010 - negative_correlation_loss: -0.9041 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9012 - negative_correlation_loss: -0.9041 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9009 - negative_correlation_loss: -0.9039 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9011 - negative_correlation_loss: -0.9041 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8868\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 5s 55ms/step - loss: -0.9013 - negative_correlation_loss: -0.9041 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9015 - negative_correlation_loss: -0.9044 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: -0.9013 - negative_correlation_loss: -0.9042 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9015 - negative_correlation_loss: -0.9043 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9015 - negative_correlation_loss: -0.9044 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8880\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9017 - negative_correlation_loss: -0.9046 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:28:45.598229: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Fold 0, correlation =  0.88974\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 49ms/step - loss: -0.8065 - negative_correlation_loss: -0.8228 - val_loss: -0.8454 - val_negative_correlation_loss: -0.8583\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8555 - negative_correlation_loss: -0.8659 - val_loss: -0.8691 - val_negative_correlation_loss: -0.8781\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8766 - negative_correlation_loss: -0.8843 - val_loss: -0.8777 - val_negative_correlation_loss: -0.8846\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8841 - negative_correlation_loss: -0.8902 - val_loss: -0.8821 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8877 - negative_correlation_loss: -0.8932 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8902 - negative_correlation_loss: -0.8955 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8913 - negative_correlation_loss: -0.8963 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8918\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8924 - negative_correlation_loss: -0.8971 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8912\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8930 - negative_correlation_loss: -0.8975 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8915\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8936 - negative_correlation_loss: -0.8980 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8922\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8937 - negative_correlation_loss: -0.8980 - val_loss: -0.8890 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8940 - negative_correlation_loss: -0.8982 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8924\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8947 - negative_correlation_loss: -0.8988 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8948 - negative_correlation_loss: -0.8988 - val_loss: -0.8898 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8950 - negative_correlation_loss: -0.8990 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8952 - negative_correlation_loss: -0.8991 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8952 - negative_correlation_loss: -0.8992 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8951 - negative_correlation_loss: -0.8991 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8919\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8957 - negative_correlation_loss: -0.8996 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8881 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 4s 45ms/step - loss: -0.8964 - negative_correlation_loss: -0.9001 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 4s 45ms/step - loss: -0.8964 - negative_correlation_loss: -0.9000 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8964 - negative_correlation_loss: -0.8999 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8962 - negative_correlation_loss: -0.8999 - val_loss: -0.8889 - val_negative_correlation_loss: -0.8925\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8964 - negative_correlation_loss: -0.9000 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8920\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8967 - negative_correlation_loss: -0.9002 - val_loss: -0.8914 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8970 - negative_correlation_loss: -0.9005 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8928\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8900 - val_negative_correlation_loss: -0.8934\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8970 - negative_correlation_loss: -0.9004 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8941\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8971 - negative_correlation_loss: -0.9005 - val_loss: -0.8912 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8906 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8975 - negative_correlation_loss: -0.9008 - val_loss: -0.8916 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8977 - negative_correlation_loss: -0.9009 - val_loss: -0.8906 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8976 - negative_correlation_loss: -0.9008 - val_loss: -0.8910 - val_negative_correlation_loss: -0.8942\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8976 - negative_correlation_loss: -0.9009 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8941\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8977 - negative_correlation_loss: -0.9009 - val_loss: -0.8911 - val_negative_correlation_loss: -0.8943\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8979 - negative_correlation_loss: -0.9011 - val_loss: -0.8923 - val_negative_correlation_loss: -0.8955\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8981 - negative_correlation_loss: -0.9012 - val_loss: -0.8915 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 4s 46ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8980 - negative_correlation_loss: -0.9011 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8913 - val_negative_correlation_loss: -0.8944\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8982 - negative_correlation_loss: -0.9013 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8983 - negative_correlation_loss: -0.9014 - val_loss: -0.8917 - val_negative_correlation_loss: -0.8947\n",
      "model saved\n",
      "Fold 1, correlation =  0.89549\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 6s 49ms/step - loss: -0.8035 - negative_correlation_loss: -0.8195 - val_loss: -0.8396 - val_negative_correlation_loss: -0.8517\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8628 - negative_correlation_loss: -0.8729 - val_loss: -0.8676 - val_negative_correlation_loss: -0.8758\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8778 - negative_correlation_loss: -0.8850 - val_loss: -0.8753 - val_negative_correlation_loss: -0.8816\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8853 - negative_correlation_loss: -0.8910 - val_loss: -0.8810 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8893 - negative_correlation_loss: -0.8944 - val_loss: -0.8813 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8910 - negative_correlation_loss: -0.8958 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8921 - negative_correlation_loss: -0.8967 - val_loss: -0.8834 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8929 - negative_correlation_loss: -0.8973 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8933 - negative_correlation_loss: -0.8975 - val_loss: -0.8825 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8938 - negative_correlation_loss: -0.8979 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8942 - negative_correlation_loss: -0.8982 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8943 - negative_correlation_loss: -0.8983 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8945 - negative_correlation_loss: -0.8984 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8892\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8948 - negative_correlation_loss: -0.8987 - val_loss: -0.8834 - val_negative_correlation_loss: -0.8872\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8949 - negative_correlation_loss: -0.8988 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 5s 56ms/step - loss: -0.8950 - negative_correlation_loss: -0.8987 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8882\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8954 - negative_correlation_loss: -0.8992 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 4s 44ms/step - loss: -0.8954 - negative_correlation_loss: -0.8991 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8957 - negative_correlation_loss: -0.8993 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8957 - negative_correlation_loss: -0.8992 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8959 - negative_correlation_loss: -0.8995 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8890\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8962 - negative_correlation_loss: -0.8996 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8965 - negative_correlation_loss: -0.8998 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8965 - negative_correlation_loss: -0.8998 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8966 - negative_correlation_loss: -0.9000 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8895\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8968 - negative_correlation_loss: -0.9000 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8968 - negative_correlation_loss: -0.9000 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8970 - negative_correlation_loss: -0.9002 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8971 - negative_correlation_loss: -0.9003 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8896\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8972 - negative_correlation_loss: -0.9004 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8971 - negative_correlation_loss: -0.9003 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8972 - negative_correlation_loss: -0.9005 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8905\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8975 - negative_correlation_loss: -0.9007 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8976 - negative_correlation_loss: -0.9007 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8976 - negative_correlation_loss: -0.9007 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8977 - negative_correlation_loss: -0.9007 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8977 - negative_correlation_loss: -0.9006 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8898\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8980 - negative_correlation_loss: -0.9009 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 4s 45ms/step - loss: -0.8980 - negative_correlation_loss: -0.9008 - val_loss: -0.8889 - val_negative_correlation_loss: -0.8917\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8980 - negative_correlation_loss: -0.9009 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8980 - negative_correlation_loss: -0.9010 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8901\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8980 - negative_correlation_loss: -0.9010 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8981 - negative_correlation_loss: -0.9010 - val_loss: -0.8888 - val_negative_correlation_loss: -0.8916\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8982 - negative_correlation_loss: -0.9010 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8983 - negative_correlation_loss: -0.9011 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8983 - negative_correlation_loss: -0.9012 - val_loss: -0.8882 - val_negative_correlation_loss: -0.8910\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8984 - negative_correlation_loss: -0.9013 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8898\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "model saved\n",
      "Fold 2, correlation =  0.89181\n",
      "\u001b[32m\u001b[1mMean corr = 0.89234\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89233\u001b[0m\n",
      "CPU times: user 30min 9s, sys: 1min 5s, total: 31min 15s\n",
      "Wall time: 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 13 min 44 s\n",
    "VERBOSE = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 50 \n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 40, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"min\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [\n",
    "                    lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6cde7f",
   "metadata": {
    "papermill": {
     "duration": 0.468248,
     "end_time": "2022-12-22T12:37:28.660421",
     "exception": false,
     "start_time": "2022-12-22T12:37:28.192173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f3385c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:37:29.658550Z",
     "iopub.status.busy": "2022-12-22T12:37:29.657926Z",
     "iopub.status.idle": "2022-12-22T12:37:44.095799Z",
     "shell.execute_reply": "2022-12-22T12:37:44.094275Z"
    },
    "papermill": {
     "duration": 14.971114,
     "end_time": "2022-12-22T12:37:44.098371",
     "exception": false,
     "start_time": "2022-12-22T12:37:29.127257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "Predicting with fold 1\n",
      "Predicting with fold 2\n",
      "CPU times: user 19.9 s, sys: 2.75 s, total: 22.7 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Around 20 s\n",
    "\n",
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153e9fc",
   "metadata": {
    "papermill": {
     "duration": 0.471902,
     "end_time": "2022-12-22T12:37:45.040066",
     "exception": false,
     "start_time": "2022-12-22T12:37:44.568164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save submission by merging with multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39b299ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:37:46.028993Z",
     "iopub.status.busy": "2022-12-22T12:37:46.028260Z",
     "iopub.status.idle": "2022-12-22T12:41:11.448707Z",
     "shell.execute_reply": "2022-12-22T12:41:11.447321Z"
    },
    "papermill": {
     "duration": 206.342536,
     "end_time": "2022-12-22T12:41:11.907477",
     "exception": false,
     "start_time": "2022-12-22T12:37:45.564941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0          -276.658997\n",
       "1          -261.586487\n",
       "2          -226.882538\n",
       "3           193.443710\n",
       "4           284.802704\n",
       "               ...    \n",
       "65744175      9.453125\n",
       "65744176      0.062561\n",
       "65744177      0.077026\n",
       "65744178      1.852539\n",
       "65744179      8.085938\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 4.76 s, total: 3min 10s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 41s\n",
    "\n",
    "# Merge with multiome\n",
    "submission = pd.read_csv(multi_ome_only_file,index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_full_m128_c64.csv')\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1518.333311,
   "end_time": "2022-12-22T12:41:15.539849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-22T12:15:57.206538",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
