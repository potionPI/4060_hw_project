{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b86102",
   "metadata": {
    "papermill": {
     "duration": 0.008606,
     "end_time": "2022-12-22T12:22:58.138973",
     "exception": false,
     "start_time": "2022-12-22T12:22:58.130367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because the datasets are SO large (especially the Multiome dataset), instead of running both parts of the project in one notebook (and risk Kaggle running out of storage space then resetting all progress), it is more convenient to separate the multiome and citeseq parts of the project, then later merge the predicted outputs from the two parts together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93561ad8",
   "metadata": {
    "papermill": {
     "duration": 0.007003,
     "end_time": "2022-12-22T12:22:58.153403",
     "exception": false,
     "start_time": "2022-12-22T12:22:58.146400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook concerns itself with the CITEseq portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1df338",
   "metadata": {
    "papermill": {
     "duration": 0.006977,
     "end_time": "2022-12-22T12:22:58.167562",
     "exception": false,
     "start_time": "2022-12-22T12:22:58.160585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First, all the basic imports and file names which may or may not be used is loaded in essentially as a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11760e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:22:58.184538Z",
     "iopub.status.busy": "2022-12-22T12:22:58.183764Z",
     "iopub.status.idle": "2022-12-22T12:23:11.799071Z",
     "shell.execute_reply": "2022-12-22T12:23:11.797333Z"
    },
    "papermill": {
     "duration": 13.627323,
     "end_time": "2022-12-22T12:23:11.802120",
     "exception": false,
     "start_time": "2022-12-22T12:22:58.174797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/conda/lib/python3.7/site-packages (3.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from tables) (1.21.6)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables) (2.8.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tables) (21.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tables) (3.0.9)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ae0dcb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-22T12:23:11.820535Z",
     "iopub.status.busy": "2022-12-22T12:23:11.820123Z",
     "iopub.status.idle": "2022-12-22T12:23:13.322999Z",
     "shell.execute_reply": "2022-12-22T12:23:13.321704Z"
    },
    "papermill": {
     "duration": 1.515436,
     "end_time": "2022-12-22T12:23:13.325795",
     "exception": false,
     "start_time": "2022-12-22T12:23:11.810359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35751f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:23:13.345316Z",
     "iopub.status.busy": "2022-12-22T12:23:13.344919Z",
     "iopub.status.idle": "2022-12-22T12:23:13.353960Z",
     "shell.execute_reply": "2022-12-22T12:23:13.352606Z"
    },
    "papermill": {
     "duration": 0.021199,
     "end_time": "2022-12-22T12:23:13.356590",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.335391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory of the data\n",
    "DATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULT_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULT_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_TARGETS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\"\n",
    "FP_MULT_TRAIN_TARGETS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\"\n",
    "FP_MULT_TEST_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TEST_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\"\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "FP_EVALUATION_IDS_parquet = \"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\"\n",
    "\n",
    "multi_ome_only_file = '../input/n32-nb2-multiome/multiome_only_32.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0ae21",
   "metadata": {
    "papermill": {
     "duration": 0.007405,
     "end_time": "2022-12-22T12:23:13.371836",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.364431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Part: Predicting protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e4b76",
   "metadata": {
    "papermill": {
     "duration": 0.007897,
     "end_time": "2022-12-22T12:23:13.387509",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.379612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the CITEseq portion begins\n",
    "\n",
    "\n",
    "Code from pourchot: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db185fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:23:13.405239Z",
     "iopub.status.busy": "2022-12-22T12:23:13.404830Z",
     "iopub.status.idle": "2022-12-22T12:23:13.410751Z",
     "shell.execute_reply": "2022-12-22T12:23:13.409025Z"
    },
    "papermill": {
     "duration": 0.017965,
     "end_time": "2022-12-22T12:23:13.413432",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.395467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_ncount = 256 # amount of dimensions to keep for SVD later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03309392",
   "metadata": {
    "papermill": {
     "duration": 0.008904,
     "end_time": "2022-12-22T12:23:13.430249",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.421345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877dc85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:23:13.449493Z",
     "iopub.status.busy": "2022-12-22T12:23:13.449093Z",
     "iopub.status.idle": "2022-12-22T12:25:34.512704Z",
     "shell.execute_reply": "2022-12-22T12:25:34.511355Z"
    },
    "papermill": {
     "duration": 141.077278,
     "end_time": "2022-12-22T12:25:34.515869",
     "exception": false,
     "start_time": "2022-12-22T12:23:13.438591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "\n",
    "# Load test inputs\n",
    "X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b9d83",
   "metadata": {
    "papermill": {
     "duration": 0.007561,
     "end_time": "2022-12-22T12:25:34.532451",
     "exception": false,
     "start_time": "2022-12-22T12:25:34.524890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Constant columns (a.k.a. columns that have the same value in all rows) are useless for machine learning. Just like if you are told to differentiate between apples and oranges, and there is a column which indicates whether apples and oranges are fruits and vegetables, both the apples and oranges will be \"fruit,\" which informs you nothing about the difference between apples and oranges.\n",
    "\n",
    "Hence, constant columns found in the training inputs are found in order to be removed from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c2a96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:34.551001Z",
     "iopub.status.busy": "2022-12-22T12:25:34.549753Z",
     "iopub.status.idle": "2022-12-22T12:25:37.330339Z",
     "shell.execute_reply": "2022-12-22T12:25:37.329164Z"
    },
    "papermill": {
     "duration": 2.79253,
     "end_time": "2022-12-22T12:25:37.332948",
     "exception": false,
     "start_time": "2022-12-22T12:25:34.540418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant columns  1194\n"
     ]
    }
   ],
   "source": [
    "constant_cols = list(X.columns[(X == 0).all(axis=0).values]) +\\\n",
    "                list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "print('constant columns ',len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11aa0e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:37.350976Z",
     "iopub.status.busy": "2022-12-22T12:25:37.350536Z",
     "iopub.status.idle": "2022-12-22T12:25:42.792891Z",
     "shell.execute_reply": "2022-12-22T12:25:42.791614Z"
    },
    "papermill": {
     "duration": 5.454945,
     "end_time": "2022-12-22T12:25:42.795729",
     "exception": false,
     "start_time": "2022-12-22T12:25:37.340784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the constant columns from the training data\n",
    "X = X.drop(columns = constant_cols)\n",
    "Xt = X_test.drop(columns = constant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234513b0",
   "metadata": {
    "papermill": {
     "duration": 0.007664,
     "end_time": "2022-12-22T12:25:42.811557",
     "exception": false,
     "start_time": "2022-12-22T12:25:42.803893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The \"important columns\" are columns that appear as training targets. Hence, it is considered important to keep them in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8de4a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:42.829726Z",
     "iopub.status.busy": "2022-12-22T12:25:42.828549Z",
     "iopub.status.idle": "2022-12-22T12:25:43.305707Z",
     "shell.execute_reply": "2022-12-22T12:25:43.304443Z"
    },
    "papermill": {
     "duration": 0.488854,
     "end_time": "2022-12-22T12:25:43.308192",
     "exception": false,
     "start_time": "2022-12-22T12:25:42.819338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important columns  144\n"
     ]
    }
   ],
   "source": [
    "important_cols = []\n",
    "for y_col in Y.columns:\n",
    "    important_cols += [x_col for x_col in X.columns if y_col in x_col]\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd33ac7",
   "metadata": {
    "papermill": {
     "duration": 0.007776,
     "end_time": "2022-12-22T12:25:43.323653",
     "exception": false,
     "start_time": "2022-12-22T12:25:43.315877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before this point, the training and testing data has been loaded in order to determine the constant columns. The training and testing data will be loaded now as sparse matrices with the constant columns removed and the important columns kept. The purpose of sparse matrices is to efficiently store data with lots of zeros and also speed up the machine learning processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e1d9810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:43.341643Z",
     "iopub.status.busy": "2022-12-22T12:25:43.341238Z",
     "iopub.status.idle": "2022-12-22T12:25:43.385477Z",
     "shell.execute_reply": "2022-12-22T12:25:43.384228Z"
    },
    "papermill": {
     "duration": 0.056455,
     "end_time": "2022-12-22T12:25:43.388114",
     "exception": false,
     "start_time": "2022-12-22T12:25:43.331659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410_A1BG</th>\n",
       "      <th>ENSG00000268895_A1BG-AS1</th>\n",
       "      <th>ENSG00000175899_A2M</th>\n",
       "      <th>ENSG00000245105_A2M-AS1</th>\n",
       "      <th>ENSG00000128274_A4GALT</th>\n",
       "      <th>ENSG00000094914_AAAS</th>\n",
       "      <th>ENSG00000081760_AACS</th>\n",
       "      <th>ENSG00000109576_AADAT</th>\n",
       "      <th>ENSG00000103591_AAGAB</th>\n",
       "      <th>ENSG00000115977_AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000153975_ZUP1</th>\n",
       "      <th>ENSG00000086827_ZW10</th>\n",
       "      <th>ENSG00000174442_ZWILCH</th>\n",
       "      <th>ENSG00000122952_ZWINT</th>\n",
       "      <th>ENSG00000198205_ZXDA</th>\n",
       "      <th>ENSG00000198455_ZXDB</th>\n",
       "      <th>ENSG00000070476_ZXDC</th>\n",
       "      <th>ENSG00000162378_ZYG11B</th>\n",
       "      <th>ENSG00000159840_ZYX</th>\n",
       "      <th>ENSG00000074755_ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.090185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>4.529743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.513782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>5.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51861</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>3.518610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410_A1BG  ENSG00000268895_A1BG-AS1  \\\n",
       "cell_id                                                        \n",
       "45006fe3e4c8                   0.0                       0.0   \n",
       "d02759a80ba2                   0.0                       0.0   \n",
       "c016c6b0efa5                   0.0                       0.0   \n",
       "ba7f733a4f75                   0.0                       0.0   \n",
       "fbcf2443ffb2                   0.0                       0.0   \n",
       "\n",
       "gene_id       ENSG00000175899_A2M  ENSG00000245105_A2M-AS1  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                  0.0                      0.0   \n",
       "d02759a80ba2                  0.0                      0.0   \n",
       "c016c6b0efa5                  0.0                      0.0   \n",
       "ba7f733a4f75                  0.0                      0.0   \n",
       "fbcf2443ffb2                  0.0                      0.0   \n",
       "\n",
       "gene_id       ENSG00000128274_A4GALT  ENSG00000094914_AAAS  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                0.000000              0.000000   \n",
       "d02759a80ba2                0.000000              0.000000   \n",
       "c016c6b0efa5                3.847321              0.000000   \n",
       "ba7f733a4f75                0.000000              3.436846   \n",
       "fbcf2443ffb2                0.000000              0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760_AACS  ENSG00000109576_AADAT  \\\n",
       "cell_id                                                     \n",
       "45006fe3e4c8              0.000000               0.000000   \n",
       "d02759a80ba2              0.000000               0.000000   \n",
       "c016c6b0efa5              3.847321               3.847321   \n",
       "ba7f733a4f75              3.436846               0.000000   \n",
       "fbcf2443ffb2              4.196826               0.000000   \n",
       "\n",
       "gene_id       ENSG00000103591_AAGAB  ENSG00000115977_AAK1  ...  \\\n",
       "cell_id                                                    ...   \n",
       "45006fe3e4c8                    0.0              0.000000  ...   \n",
       "d02759a80ba2                    0.0              4.039545  ...   \n",
       "c016c6b0efa5                    0.0              0.000000  ...   \n",
       "ba7f733a4f75                    0.0              4.513782  ...   \n",
       "fbcf2443ffb2                    0.0              0.000000  ...   \n",
       "\n",
       "gene_id       ENSG00000153975_ZUP1  ENSG00000086827_ZW10  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8              0.000000              0.000000   \n",
       "d02759a80ba2              0.000000              0.000000   \n",
       "c016c6b0efa5              0.000000              0.000000   \n",
       "ba7f733a4f75              3.436846              0.000000   \n",
       "fbcf2443ffb2              0.000000              4.196826   \n",
       "\n",
       "gene_id       ENSG00000174442_ZWILCH  ENSG00000122952_ZWINT  \\\n",
       "cell_id                                                       \n",
       "45006fe3e4c8                0.000000               0.000000   \n",
       "d02759a80ba2                0.000000               4.039545   \n",
       "c016c6b0efa5                3.847321               4.529743   \n",
       "ba7f733a4f75                4.113780               5.020215   \n",
       "fbcf2443ffb2                4.196826               4.196826   \n",
       "\n",
       "gene_id       ENSG00000198205_ZXDA  ENSG00000198455_ZXDB  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8                   0.0                   0.0   \n",
       "d02759a80ba2                   0.0                   0.0   \n",
       "c016c6b0efa5                   0.0                   0.0   \n",
       "ba7f733a4f75                   0.0                   0.0   \n",
       "fbcf2443ffb2                   0.0                   0.0   \n",
       "\n",
       "gene_id       ENSG00000070476_ZXDC  ENSG00000162378_ZYG11B  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8               0.00000                0.000000   \n",
       "d02759a80ba2               0.00000                0.000000   \n",
       "c016c6b0efa5               0.00000                3.847321   \n",
       "ba7f733a4f75               0.00000                3.436846   \n",
       "fbcf2443ffb2               3.51861                4.196826   \n",
       "\n",
       "gene_id       ENSG00000159840_ZYX  ENSG00000074755_ZZEF1  \n",
       "cell_id                                                   \n",
       "45006fe3e4c8             4.090185                    0.0  \n",
       "d02759a80ba2             0.000000                    0.0  \n",
       "c016c6b0efa5             3.847321                    0.0  \n",
       "ba7f733a4f75             4.113780                    0.0  \n",
       "fbcf2443ffb2             3.518610                    0.0  \n",
       "\n",
       "[5 rows x 20856 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, taking a look at X shows there are a LOT of zeros:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f064f8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:43.406726Z",
     "iopub.status.busy": "2022-12-22T12:25:43.406281Z",
     "iopub.status.idle": "2022-12-22T12:25:43.919789Z",
     "shell.execute_reply": "2022-12-22T12:25:43.918606Z"
    },
    "papermill": {
     "duration": 0.525728,
     "end_time": "2022-12-22T12:25:43.922291",
     "exception": false,
     "start_time": "2022-12-22T12:25:43.396563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119651, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first delete the X, X_test, Xt, and Y to save space\n",
    "del X\n",
    "del X_test\n",
    "del Xt\n",
    "del Y\n",
    "\n",
    "# load in the metadata since it'll be modified as well in the next cell\n",
    "# (Since X and Y are modified, it is convenient to modify the metadata to match\n",
    "# at the same time)\n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"] # focus on citeseq right now\n",
    "metadata_df.shape # show the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46bf38e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:25:43.940928Z",
     "iopub.status.busy": "2022-12-22T12:25:43.940485Z",
     "iopub.status.idle": "2022-12-22T12:30:13.228077Z",
     "shell.execute_reply": "2022-12-22T12:30:13.225988Z"
    },
    "papermill": {
     "duration": 269.30808,
     "end_time": "2022-12-22T12:30:13.238734",
     "exception": false,
     "start_time": "2022-12-22T12:25:43.930654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (70988, 20856) 5.515 GByte\n",
      "Original Xt shape: (48663, 20856) 3.781 GByte\n",
      "CPU times: user 3min 36s, sys: 19.2 s, total: 3min 55s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 17s\n",
    "\n",
    "# Now, the data will be converted into sparse matrices\n",
    "# (See MSCI CITEseq Keras Quickstart by AMBROSM)\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "print(f\"Original X shape: {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "X = scipy.sparse.csr_matrix(X.values)\n",
    "gc.collect()\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "print(f\"Original Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "Xt = scipy.sparse.csr_matrix(Xt.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f41a1b",
   "metadata": {
    "papermill": {
     "duration": 0.008366,
     "end_time": "2022-12-22T12:30:13.256432",
     "exception": false,
     "start_time": "2022-12-22T12:30:13.248066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform SVD\n",
    "Now perform SVD in order to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a014485a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:13.276002Z",
     "iopub.status.busy": "2022-12-22T12:30:13.275548Z",
     "iopub.status.idle": "2022-12-22T12:50:54.200416Z",
     "shell.execute_reply": "2022-12-22T12:50:54.198780Z"
    },
    "papermill": {
     "duration": 1240.947009,
     "end_time": "2022-12-22T12:50:54.212378",
     "exception": false,
     "start_time": "2022-12-22T12:30:13.265369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (119651, 20856)\n",
      "Shape of both after SVD:  (119651, 256)\n",
      "Reduced X shape:  (70988, 400)   0.106 GByte\n",
      "Reduced Xt shape: (48663, 400)   0.073 GByte\n",
      "CPU times: user 20min 43s, sys: 12.5 s, total: 20min 55s\n",
      "Wall time: 20min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5-6 minutes\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "assert both.shape[0] == 119651\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n",
    "svd = TruncatedSVD(n_components=svd_ncount, random_state=1) # 512 is possible\n",
    "both = svd.fit_transform(both)\n",
    "print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:70988]\n",
    "Xt = both[70988:]\n",
    "del both\n",
    "X = np.hstack([X, X0])\n",
    "Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f62d71e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:50:54.233250Z",
     "iopub.status.busy": "2022-12-22T12:50:54.232764Z",
     "iopub.status.idle": "2022-12-22T12:50:54.239902Z",
     "shell.execute_reply": "2022-12-22T12:50:54.238648Z"
    },
    "papermill": {
     "duration": 0.020998,
     "end_time": "2022-12-22T12:50:54.242339",
     "exception": false,
     "start_time": "2022-12-22T12:50:54.221341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:\n",
      "0.16751328\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\")\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21672880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:50:54.264205Z",
     "iopub.status.busy": "2022-12-22T12:50:54.263142Z",
     "iopub.status.idle": "2022-12-22T12:50:55.005977Z",
     "shell.execute_reply": "2022-12-22T12:50:55.004662Z"
    },
    "papermill": {
     "duration": 0.755883,
     "end_time": "2022-12-22T12:50:55.008418",
     "exception": false,
     "start_time": "2022-12-22T12:50:54.252535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (70988, 140)   0.037 GByte\n"
     ]
    }
   ],
   "source": [
    "# Read Y\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "y_columns = list(Y.columns)\n",
    "Y = Y.values\n",
    "\n",
    "# Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# and negative_correlation_loss depends on it\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce54b1",
   "metadata": {
    "papermill": {
     "duration": 0.008599,
     "end_time": "2022-12-22T12:50:55.026048",
     "exception": false,
     "start_time": "2022-12-22T12:50:55.017449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CITEseq learning model\n",
    "\n",
    "From: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85026e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:50:55.045930Z",
     "iopub.status.busy": "2022-12-22T12:50:55.045491Z",
     "iopub.status.idle": "2022-12-22T12:51:02.154957Z",
     "shell.execute_reply": "2022-12-22T12:51:02.153981Z"
    },
    "papermill": {
     "duration": 7.122475,
     "end_time": "2022-12-22T12:51:02.157578",
     "exception": false,
     "start_time": "2022-12-22T12:50:55.035103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c32750",
   "metadata": {
    "papermill": {
     "duration": 0.008896,
     "end_time": "2022-12-22T12:51:02.176580",
     "exception": false,
     "start_time": "2022-12-22T12:51:02.167684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metric and loss function from MSCI CITEseq Keras Quickstart by AMBROSM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f3996c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:51:02.198926Z",
     "iopub.status.busy": "2022-12-22T12:51:02.197131Z",
     "iopub.status.idle": "2022-12-22T12:51:02.209713Z",
     "shell.execute_reply": "2022-12-22T12:51:02.208427Z"
    },
    "papermill": {
     "duration": 0.025973,
     "end_time": "2022-12-22T12:51:02.212645",
     "exception": false,
     "start_time": "2022-12-22T12:51:02.186672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e70efda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:51:02.233612Z",
     "iopub.status.busy": "2022-12-22T12:51:02.233197Z",
     "iopub.status.idle": "2022-12-22T12:51:02.244946Z",
     "shell.execute_reply": "2022-12-22T12:51:02.243296Z"
    },
    "papermill": {
     "duration": 0.026327,
     "end_time": "2022-12-22T12:51:02.248017",
     "exception": false,
     "start_time": "2022-12-22T12:51:02.221690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(256, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1) \n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2)\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efaca84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:51:02.271728Z",
     "iopub.status.busy": "2022-12-22T12:51:02.271267Z",
     "iopub.status.idle": "2022-12-22T13:03:41.508828Z",
     "shell.execute_reply": "2022-12-22T13:03:41.507376Z"
    },
    "papermill": {
     "duration": 759.252693,
     "end_time": "2022-12-22T13:03:41.511739",
     "exception": false,
     "start_time": "2022-12-22T12:51:02.259046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:51:02.603940: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-22 12:51:02.903898: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 6s 52ms/step - loss: -0.8231 - negative_correlation_loss: -0.8405 - val_loss: -0.8552 - val_negative_correlation_loss: -0.8686\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 5s 57ms/step - loss: -0.8766 - negative_correlation_loss: -0.8879 - val_loss: -0.8697 - val_negative_correlation_loss: -0.8787\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8863 - negative_correlation_loss: -0.8943 - val_loss: -0.8734 - val_negative_correlation_loss: -0.8803\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8903 - negative_correlation_loss: -0.8971 - val_loss: -0.8778 - val_negative_correlation_loss: -0.8839\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8930 - negative_correlation_loss: -0.8991 - val_loss: -0.8798 - val_negative_correlation_loss: -0.8852\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8946 - negative_correlation_loss: -0.9002 - val_loss: -0.8804 - val_negative_correlation_loss: -0.8856\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8952 - negative_correlation_loss: -0.9006 - val_loss: -0.8807 - val_negative_correlation_loss: -0.8856\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8960 - negative_correlation_loss: -0.9011 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8864\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 5s 57ms/step - loss: -0.8965 - negative_correlation_loss: -0.9014 - val_loss: -0.8821 - val_negative_correlation_loss: -0.8868\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8969 - negative_correlation_loss: -0.9018 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.8972 - negative_correlation_loss: -0.9020 - val_loss: -0.8820 - val_negative_correlation_loss: -0.8864\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8973 - negative_correlation_loss: -0.9020 - val_loss: -0.8827 - val_negative_correlation_loss: -0.8872\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8975 - negative_correlation_loss: -0.9022 - val_loss: -0.8818 - val_negative_correlation_loss: -0.8862\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8978 - negative_correlation_loss: -0.9024 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8861\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8983 - negative_correlation_loss: -0.9027 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 5s 55ms/step - loss: -0.8984 - negative_correlation_loss: -0.9029 - val_loss: -0.8821 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8986 - negative_correlation_loss: -0.9030 - val_loss: -0.8812 - val_negative_correlation_loss: -0.8853\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8986 - negative_correlation_loss: -0.9030 - val_loss: -0.8835 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8988 - negative_correlation_loss: -0.9030 - val_loss: -0.8838 - val_negative_correlation_loss: -0.8878\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8991 - negative_correlation_loss: -0.9034 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8992 - negative_correlation_loss: -0.9034 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8993 - negative_correlation_loss: -0.9035 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.8995 - negative_correlation_loss: -0.9036 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8993 - negative_correlation_loss: -0.9035 - val_loss: -0.8838 - val_negative_correlation_loss: -0.8877\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8997 - negative_correlation_loss: -0.9038 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8998 - negative_correlation_loss: -0.9038 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9000 - negative_correlation_loss: -0.9039 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8998 - negative_correlation_loss: -0.9038 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8999 - negative_correlation_loss: -0.9039 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 5s 55ms/step - loss: -0.8998 - negative_correlation_loss: -0.9038 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9000 - negative_correlation_loss: -0.9040 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8999 - negative_correlation_loss: -0.9039 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8999 - negative_correlation_loss: -0.9040 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9000 - negative_correlation_loss: -0.9040 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9000 - negative_correlation_loss: -0.9040 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9000 - negative_correlation_loss: -0.9039 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8888\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.9005 - negative_correlation_loss: -0.9044 - val_loss: -0.8833 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9006 - negative_correlation_loss: -0.9046 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9005 - negative_correlation_loss: -0.9044 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9006 - negative_correlation_loss: -0.9045 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9004 - negative_correlation_loss: -0.9044 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9006 - negative_correlation_loss: -0.9044 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9002 - negative_correlation_loss: -0.9042 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 5s 58ms/step - loss: -0.9005 - negative_correlation_loss: -0.9044 - val_loss: -0.8830 - val_negative_correlation_loss: -0.8867\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9008 - negative_correlation_loss: -0.9045 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9008 - negative_correlation_loss: -0.9046 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9008 - negative_correlation_loss: -0.9045 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.9010 - negative_correlation_loss: -0.9047 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8875\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9013 - negative_correlation_loss: -0.9049 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9014 - negative_correlation_loss: -0.9050 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:54:50.718639: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Fold 0, correlation =  0.89005\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 52ms/step - loss: -0.8034 - negative_correlation_loss: -0.8207 - val_loss: -0.8453 - val_negative_correlation_loss: -0.8589\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8541 - negative_correlation_loss: -0.8652 - val_loss: -0.8669 - val_negative_correlation_loss: -0.8764\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8748 - negative_correlation_loss: -0.8831 - val_loss: -0.8760 - val_negative_correlation_loss: -0.8834\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8829 - negative_correlation_loss: -0.8896 - val_loss: -0.8819 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8873 - negative_correlation_loss: -0.8935 - val_loss: -0.8833 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8897 - negative_correlation_loss: -0.8957 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8912\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8909 - negative_correlation_loss: -0.8966 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8920\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8920 - negative_correlation_loss: -0.8974 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8910\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8926 - negative_correlation_loss: -0.8978 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8916\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8931 - negative_correlation_loss: -0.8983 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8932 - negative_correlation_loss: -0.8984 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8927\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8937 - negative_correlation_loss: -0.8987 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8940 - negative_correlation_loss: -0.8989 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8926\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8940 - negative_correlation_loss: -0.8989 - val_loss: -0.8882 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8943 - negative_correlation_loss: -0.8992 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8943 - negative_correlation_loss: -0.8991 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8950 - negative_correlation_loss: -0.8997 - val_loss: -0.8891 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8954 - negative_correlation_loss: -0.8999 - val_loss: -0.8891 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 7s 73ms/step - loss: -0.8954 - negative_correlation_loss: -0.8999 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8952 - negative_correlation_loss: -0.8998 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8932\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8954 - negative_correlation_loss: -0.9000 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8920\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8955 - negative_correlation_loss: -0.9001 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8926\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8955 - negative_correlation_loss: -0.9001 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8931\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8958 - negative_correlation_loss: -0.9003 - val_loss: -0.8890 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8963 - negative_correlation_loss: -0.9006 - val_loss: -0.8897 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8962 - negative_correlation_loss: -0.9006 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8961 - negative_correlation_loss: -0.9005 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8931\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8960 - negative_correlation_loss: -0.9005 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8922\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8962 - negative_correlation_loss: -0.9006 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8928\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8966 - negative_correlation_loss: -0.9009 - val_loss: -0.8904 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8894 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8967 - negative_correlation_loss: -0.9010 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8921\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8967 - negative_correlation_loss: -0.9010 - val_loss: -0.8895 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8968 - negative_correlation_loss: -0.9011 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8968 - negative_correlation_loss: -0.9010 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8895 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8968 - negative_correlation_loss: -0.9010 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8928\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8971 - negative_correlation_loss: -0.9013 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8974 - negative_correlation_loss: -0.9015 - val_loss: -0.8897 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8974 - negative_correlation_loss: -0.9015 - val_loss: -0.8890 - val_negative_correlation_loss: -0.8931\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8972 - negative_correlation_loss: -0.9014 - val_loss: -0.8888 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8973 - negative_correlation_loss: -0.9015 - val_loss: -0.8895 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 49ms/step - loss: -0.8978 - negative_correlation_loss: -0.9018 - val_loss: -0.8915 - val_negative_correlation_loss: -0.8955\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8979 - negative_correlation_loss: -0.9020 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8978 - negative_correlation_loss: -0.9018 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8979 - negative_correlation_loss: -0.9019 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8945\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8978 - negative_correlation_loss: -0.9019 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8983 - negative_correlation_loss: -0.9022 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 50ms/step - loss: -0.8983 - negative_correlation_loss: -0.9022 - val_loss: -0.8904 - val_negative_correlation_loss: -0.8943\n",
      "model saved\n",
      "Fold 1, correlation =  0.89547\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 6s 52ms/step - loss: -0.8058 - negative_correlation_loss: -0.8226 - val_loss: -0.8556 - val_negative_correlation_loss: -0.8688\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8697 - negative_correlation_loss: -0.8807 - val_loss: -0.8695 - val_negative_correlation_loss: -0.8783\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8801 - negative_correlation_loss: -0.8880 - val_loss: -0.8759 - val_negative_correlation_loss: -0.8827\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8862 - negative_correlation_loss: -0.8926 - val_loss: -0.8804 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8889 - negative_correlation_loss: -0.8950 - val_loss: -0.8818 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8909 - negative_correlation_loss: -0.8965 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8919 - negative_correlation_loss: -0.8972 - val_loss: -0.8821 - val_negative_correlation_loss: -0.8871\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8925 - negative_correlation_loss: -0.8977 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8928 - negative_correlation_loss: -0.8979 - val_loss: -0.8824 - val_negative_correlation_loss: -0.8873\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8933 - negative_correlation_loss: -0.8982 - val_loss: -0.8838 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8937 - negative_correlation_loss: -0.8985 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8939 - negative_correlation_loss: -0.8987 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8940 - negative_correlation_loss: -0.8988 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 5s 56ms/step - loss: -0.8944 - negative_correlation_loss: -0.8990 - val_loss: -0.8829 - val_negative_correlation_loss: -0.8875\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8943 - negative_correlation_loss: -0.8990 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8945 - negative_correlation_loss: -0.8991 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8947 - negative_correlation_loss: -0.8993 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8947 - negative_correlation_loss: -0.8992 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8948 - negative_correlation_loss: -0.8994 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 6s 59ms/step - loss: -0.8949 - negative_correlation_loss: -0.8993 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 5s 49ms/step - loss: -0.8951 - negative_correlation_loss: -0.8996 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8892\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8951 - negative_correlation_loss: -0.8995 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8953 - negative_correlation_loss: -0.8998 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8904\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 11s 112ms/step - loss: -0.8957 - negative_correlation_loss: -0.9000 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 12s 128ms/step - loss: -0.8957 - negative_correlation_loss: -0.9000 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 6s 59ms/step - loss: -0.8958 - negative_correlation_loss: -0.9000 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 7s 74ms/step - loss: -0.8958 - negative_correlation_loss: -0.9001 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 6s 57ms/step - loss: -0.8957 - negative_correlation_loss: -0.8999 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8913\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 7s 70ms/step - loss: -0.8959 - negative_correlation_loss: -0.9002 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 6s 66ms/step - loss: -0.8958 - negative_correlation_loss: -0.9001 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 6s 59ms/step - loss: -0.8960 - negative_correlation_loss: -0.9002 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8959 - negative_correlation_loss: -0.9002 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8897\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8963 - negative_correlation_loss: -0.9005 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8963 - negative_correlation_loss: -0.9004 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 5s 57ms/step - loss: -0.8962 - negative_correlation_loss: -0.9005 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8964 - negative_correlation_loss: -0.9006 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8905\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8967 - negative_correlation_loss: -0.9008 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8911\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8967 - negative_correlation_loss: -0.9008 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8969 - negative_correlation_loss: -0.9009 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8968 - negative_correlation_loss: -0.9008 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8905\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 6s 63ms/step - loss: -0.8972 - negative_correlation_loss: -0.9011 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 6s 60ms/step - loss: -0.8973 - negative_correlation_loss: -0.9010 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8910\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8973 - negative_correlation_loss: -0.9012 - val_loss: -0.8881 - val_negative_correlation_loss: -0.8918\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8973 - negative_correlation_loss: -0.9011 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8973 - negative_correlation_loss: -0.9012 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8895\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: -0.8974 - negative_correlation_loss: -0.9012 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8913\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8973 - negative_correlation_loss: -0.9011 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8899\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8977 - negative_correlation_loss: -0.9014 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8911\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8977 - negative_correlation_loss: -0.9015 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8911\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: -0.8978 - negative_correlation_loss: -0.9016 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8906\n",
      "model saved\n",
      "Fold 2, correlation =  0.89192\n",
      "\u001b[32m\u001b[1mMean corr = 0.89248\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89247\u001b[0m\n",
      "CPU times: user 32min 12s, sys: 1min 11s, total: 33min 24s\n",
      "Wall time: 12min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 13 min 44 s\n",
    "VERBOSE = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 50 \n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 40, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"min\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [\n",
    "                    lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae8615f",
   "metadata": {
    "papermill": {
     "duration": 0.502141,
     "end_time": "2022-12-22T13:03:42.528817",
     "exception": false,
     "start_time": "2022-12-22T13:03:42.026676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beaeb521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T13:03:43.607087Z",
     "iopub.status.busy": "2022-12-22T13:03:43.605940Z",
     "iopub.status.idle": "2022-12-22T13:03:58.772242Z",
     "shell.execute_reply": "2022-12-22T13:03:58.770905Z"
    },
    "papermill": {
     "duration": 15.752136,
     "end_time": "2022-12-22T13:03:58.775041",
     "exception": false,
     "start_time": "2022-12-22T13:03:43.022905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "Predicting with fold 1\n",
      "Predicting with fold 2\n",
      "CPU times: user 21.1 s, sys: 2.85 s, total: 23.9 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Around 20 s\n",
    "\n",
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506020d1",
   "metadata": {
    "papermill": {
     "duration": 0.488628,
     "end_time": "2022-12-22T13:03:59.747431",
     "exception": false,
     "start_time": "2022-12-22T13:03:59.258803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save submission by merging with multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b9e478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T13:04:00.802380Z",
     "iopub.status.busy": "2022-12-22T13:04:00.801494Z",
     "iopub.status.idle": "2022-12-22T13:07:43.886461Z",
     "shell.execute_reply": "2022-12-22T13:07:43.884521Z"
    },
    "papermill": {
     "duration": 224.101773,
     "end_time": "2022-12-22T13:07:44.401125",
     "exception": false,
     "start_time": "2022-12-22T13:04:00.299352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0          -301.734344\n",
       "1          -299.683777\n",
       "2          -253.659958\n",
       "3           188.488892\n",
       "4           291.168732\n",
       "               ...    \n",
       "65744175      6.183594\n",
       "65744176      0.044525\n",
       "65744177      0.039185\n",
       "65744178      1.047852\n",
       "65744179      5.597656\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 13s, sys: 16.5 s, total: 3min 29s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 41s\n",
    "\n",
    "# Merge with multiome\n",
    "submission = pd.read_csv(multi_ome_only_file,index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_full_m32_c256.csv')\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2701.326511,
   "end_time": "2022-12-22T13:07:48.249368",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-22T12:22:46.922857",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
