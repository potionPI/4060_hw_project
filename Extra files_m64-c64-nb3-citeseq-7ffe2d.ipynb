{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751ea3ef",
   "metadata": {
    "papermill": {
     "duration": 0.008725,
     "end_time": "2022-12-22T12:28:32.570128",
     "exception": false,
     "start_time": "2022-12-22T12:28:32.561403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because the datasets are SO large (especially the Multiome dataset), instead of running both parts of the project in one notebook (and risk Kaggle running out of storage space then resetting all progress), it is more convenient to separate the multiome and citeseq parts of the project, then later merge the predicted outputs from the two parts together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d820d9",
   "metadata": {
    "papermill": {
     "duration": 0.00694,
     "end_time": "2022-12-22T12:28:32.584530",
     "exception": false,
     "start_time": "2022-12-22T12:28:32.577590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook concerns itself with the CITEseq portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354e072",
   "metadata": {
    "papermill": {
     "duration": 0.006935,
     "end_time": "2022-12-22T12:28:32.598591",
     "exception": false,
     "start_time": "2022-12-22T12:28:32.591656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First, all the basic imports and file names which may or may not be used is loaded in essentially as a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec7c9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:28:32.614934Z",
     "iopub.status.busy": "2022-12-22T12:28:32.614515Z",
     "iopub.status.idle": "2022-12-22T12:28:44.678590Z",
     "shell.execute_reply": "2022-12-22T12:28:44.677597Z"
    },
    "papermill": {
     "duration": 12.075731,
     "end_time": "2022-12-22T12:28:44.681455",
     "exception": false,
     "start_time": "2022-12-22T12:28:32.605724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/conda/lib/python3.7/site-packages (3.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from tables) (1.21.6)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables) (2.8.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tables) (21.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tables) (3.0.9)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f4b408",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-22T12:28:44.698694Z",
     "iopub.status.busy": "2022-12-22T12:28:44.698320Z",
     "iopub.status.idle": "2022-12-22T12:28:45.857921Z",
     "shell.execute_reply": "2022-12-22T12:28:45.856769Z"
    },
    "papermill": {
     "duration": 1.171527,
     "end_time": "2022-12-22T12:28:45.860740",
     "exception": false,
     "start_time": "2022-12-22T12:28:44.689213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04992643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:28:45.879083Z",
     "iopub.status.busy": "2022-12-22T12:28:45.878655Z",
     "iopub.status.idle": "2022-12-22T12:28:45.887057Z",
     "shell.execute_reply": "2022-12-22T12:28:45.885859Z"
    },
    "papermill": {
     "duration": 0.019388,
     "end_time": "2022-12-22T12:28:45.889304",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.869916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory of the data\n",
    "DATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULT_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULT_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_TARGETS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\"\n",
    "FP_MULT_TRAIN_TARGETS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\"\n",
    "FP_MULT_TEST_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TEST_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\"\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "FP_EVALUATION_IDS_parquet = \"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\"\n",
    "\n",
    "multi_ome_only_file = '../input/n64-nb2-multiome/multiome_only_64.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784164d",
   "metadata": {
    "papermill": {
     "duration": 0.007172,
     "end_time": "2022-12-22T12:28:45.904086",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.896914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Part: Predicting protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91a7fe",
   "metadata": {
    "papermill": {
     "duration": 0.007153,
     "end_time": "2022-12-22T12:28:45.919109",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.911956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the CITEseq portion begins\n",
    "\n",
    "\n",
    "Code from pourchot: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c8554e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:28:45.935557Z",
     "iopub.status.busy": "2022-12-22T12:28:45.935167Z",
     "iopub.status.idle": "2022-12-22T12:28:45.940030Z",
     "shell.execute_reply": "2022-12-22T12:28:45.938987Z"
    },
    "papermill": {
     "duration": 0.015443,
     "end_time": "2022-12-22T12:28:45.941937",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.926494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_ncount = 64 # amount of dimensions to keep for SVD later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956432c6",
   "metadata": {
    "papermill": {
     "duration": 0.007203,
     "end_time": "2022-12-22T12:28:45.956539",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.949336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0692e472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:28:45.973579Z",
     "iopub.status.busy": "2022-12-22T12:28:45.972865Z",
     "iopub.status.idle": "2022-12-22T12:30:09.610783Z",
     "shell.execute_reply": "2022-12-22T12:30:09.608246Z"
    },
    "papermill": {
     "duration": 83.652306,
     "end_time": "2022-12-22T12:30:09.616189",
     "exception": false,
     "start_time": "2022-12-22T12:28:45.963883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "\n",
    "# Load test inputs\n",
    "X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e10eec",
   "metadata": {
    "papermill": {
     "duration": 0.007492,
     "end_time": "2022-12-22T12:30:09.634417",
     "exception": false,
     "start_time": "2022-12-22T12:30:09.626925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Constant columns (a.k.a. columns that have the same value in all rows) are useless for machine learning. Just like if you are told to differentiate between apples and oranges, and there is a column which indicates whether apples and oranges are fruits and vegetables, both the apples and oranges will be \"fruit,\" which informs you nothing about the difference between apples and oranges.\n",
    "\n",
    "Hence, constant columns found in the training inputs are found in order to be removed from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72dcbf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:09.652351Z",
     "iopub.status.busy": "2022-12-22T12:30:09.651883Z",
     "iopub.status.idle": "2022-12-22T12:30:12.279672Z",
     "shell.execute_reply": "2022-12-22T12:30:12.278433Z"
    },
    "papermill": {
     "duration": 2.640053,
     "end_time": "2022-12-22T12:30:12.282083",
     "exception": false,
     "start_time": "2022-12-22T12:30:09.642030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant columns  1194\n"
     ]
    }
   ],
   "source": [
    "constant_cols = list(X.columns[(X == 0).all(axis=0).values]) +\\\n",
    "                list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "print('constant columns ',len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fff707e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:12.299670Z",
     "iopub.status.busy": "2022-12-22T12:30:12.299299Z",
     "iopub.status.idle": "2022-12-22T12:30:15.386946Z",
     "shell.execute_reply": "2022-12-22T12:30:15.385768Z"
    },
    "papermill": {
     "duration": 3.099798,
     "end_time": "2022-12-22T12:30:15.389637",
     "exception": false,
     "start_time": "2022-12-22T12:30:12.289839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the constant columns from the training data\n",
    "X = X.drop(columns = constant_cols)\n",
    "Xt = X_test.drop(columns = constant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205aa8f",
   "metadata": {
    "papermill": {
     "duration": 0.007628,
     "end_time": "2022-12-22T12:30:15.406011",
     "exception": false,
     "start_time": "2022-12-22T12:30:15.398383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The \"important columns\" are columns that appear as training targets. Hence, it is considered important to keep them in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea817b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:15.423721Z",
     "iopub.status.busy": "2022-12-22T12:30:15.423303Z",
     "iopub.status.idle": "2022-12-22T12:30:15.862988Z",
     "shell.execute_reply": "2022-12-22T12:30:15.861564Z"
    },
    "papermill": {
     "duration": 0.451887,
     "end_time": "2022-12-22T12:30:15.865715",
     "exception": false,
     "start_time": "2022-12-22T12:30:15.413828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important columns  144\n"
     ]
    }
   ],
   "source": [
    "important_cols = []\n",
    "for y_col in Y.columns:\n",
    "    important_cols += [x_col for x_col in X.columns if y_col in x_col]\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34417c",
   "metadata": {
    "papermill": {
     "duration": 0.00771,
     "end_time": "2022-12-22T12:30:15.881555",
     "exception": false,
     "start_time": "2022-12-22T12:30:15.873845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before this point, the training and testing data has been loaded in order to determine the constant columns. The training and testing data will be loaded now as sparse matrices with the constant columns removed and the important columns kept. The purpose of sparse matrices is to efficiently store data with lots of zeros and also speed up the machine learning processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc06526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:15.898974Z",
     "iopub.status.busy": "2022-12-22T12:30:15.898552Z",
     "iopub.status.idle": "2022-12-22T12:30:15.943371Z",
     "shell.execute_reply": "2022-12-22T12:30:15.942150Z"
    },
    "papermill": {
     "duration": 0.057261,
     "end_time": "2022-12-22T12:30:15.946660",
     "exception": false,
     "start_time": "2022-12-22T12:30:15.889399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410_A1BG</th>\n",
       "      <th>ENSG00000268895_A1BG-AS1</th>\n",
       "      <th>ENSG00000175899_A2M</th>\n",
       "      <th>ENSG00000245105_A2M-AS1</th>\n",
       "      <th>ENSG00000128274_A4GALT</th>\n",
       "      <th>ENSG00000094914_AAAS</th>\n",
       "      <th>ENSG00000081760_AACS</th>\n",
       "      <th>ENSG00000109576_AADAT</th>\n",
       "      <th>ENSG00000103591_AAGAB</th>\n",
       "      <th>ENSG00000115977_AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000153975_ZUP1</th>\n",
       "      <th>ENSG00000086827_ZW10</th>\n",
       "      <th>ENSG00000174442_ZWILCH</th>\n",
       "      <th>ENSG00000122952_ZWINT</th>\n",
       "      <th>ENSG00000198205_ZXDA</th>\n",
       "      <th>ENSG00000198455_ZXDB</th>\n",
       "      <th>ENSG00000070476_ZXDC</th>\n",
       "      <th>ENSG00000162378_ZYG11B</th>\n",
       "      <th>ENSG00000159840_ZYX</th>\n",
       "      <th>ENSG00000074755_ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.090185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>4.529743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.513782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>5.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51861</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>3.518610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410_A1BG  ENSG00000268895_A1BG-AS1  \\\n",
       "cell_id                                                        \n",
       "45006fe3e4c8                   0.0                       0.0   \n",
       "d02759a80ba2                   0.0                       0.0   \n",
       "c016c6b0efa5                   0.0                       0.0   \n",
       "ba7f733a4f75                   0.0                       0.0   \n",
       "fbcf2443ffb2                   0.0                       0.0   \n",
       "\n",
       "gene_id       ENSG00000175899_A2M  ENSG00000245105_A2M-AS1  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                  0.0                      0.0   \n",
       "d02759a80ba2                  0.0                      0.0   \n",
       "c016c6b0efa5                  0.0                      0.0   \n",
       "ba7f733a4f75                  0.0                      0.0   \n",
       "fbcf2443ffb2                  0.0                      0.0   \n",
       "\n",
       "gene_id       ENSG00000128274_A4GALT  ENSG00000094914_AAAS  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                0.000000              0.000000   \n",
       "d02759a80ba2                0.000000              0.000000   \n",
       "c016c6b0efa5                3.847321              0.000000   \n",
       "ba7f733a4f75                0.000000              3.436846   \n",
       "fbcf2443ffb2                0.000000              0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760_AACS  ENSG00000109576_AADAT  \\\n",
       "cell_id                                                     \n",
       "45006fe3e4c8              0.000000               0.000000   \n",
       "d02759a80ba2              0.000000               0.000000   \n",
       "c016c6b0efa5              3.847321               3.847321   \n",
       "ba7f733a4f75              3.436846               0.000000   \n",
       "fbcf2443ffb2              4.196826               0.000000   \n",
       "\n",
       "gene_id       ENSG00000103591_AAGAB  ENSG00000115977_AAK1  ...  \\\n",
       "cell_id                                                    ...   \n",
       "45006fe3e4c8                    0.0              0.000000  ...   \n",
       "d02759a80ba2                    0.0              4.039545  ...   \n",
       "c016c6b0efa5                    0.0              0.000000  ...   \n",
       "ba7f733a4f75                    0.0              4.513782  ...   \n",
       "fbcf2443ffb2                    0.0              0.000000  ...   \n",
       "\n",
       "gene_id       ENSG00000153975_ZUP1  ENSG00000086827_ZW10  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8              0.000000              0.000000   \n",
       "d02759a80ba2              0.000000              0.000000   \n",
       "c016c6b0efa5              0.000000              0.000000   \n",
       "ba7f733a4f75              3.436846              0.000000   \n",
       "fbcf2443ffb2              0.000000              4.196826   \n",
       "\n",
       "gene_id       ENSG00000174442_ZWILCH  ENSG00000122952_ZWINT  \\\n",
       "cell_id                                                       \n",
       "45006fe3e4c8                0.000000               0.000000   \n",
       "d02759a80ba2                0.000000               4.039545   \n",
       "c016c6b0efa5                3.847321               4.529743   \n",
       "ba7f733a4f75                4.113780               5.020215   \n",
       "fbcf2443ffb2                4.196826               4.196826   \n",
       "\n",
       "gene_id       ENSG00000198205_ZXDA  ENSG00000198455_ZXDB  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8                   0.0                   0.0   \n",
       "d02759a80ba2                   0.0                   0.0   \n",
       "c016c6b0efa5                   0.0                   0.0   \n",
       "ba7f733a4f75                   0.0                   0.0   \n",
       "fbcf2443ffb2                   0.0                   0.0   \n",
       "\n",
       "gene_id       ENSG00000070476_ZXDC  ENSG00000162378_ZYG11B  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8               0.00000                0.000000   \n",
       "d02759a80ba2               0.00000                0.000000   \n",
       "c016c6b0efa5               0.00000                3.847321   \n",
       "ba7f733a4f75               0.00000                3.436846   \n",
       "fbcf2443ffb2               3.51861                4.196826   \n",
       "\n",
       "gene_id       ENSG00000159840_ZYX  ENSG00000074755_ZZEF1  \n",
       "cell_id                                                   \n",
       "45006fe3e4c8             4.090185                    0.0  \n",
       "d02759a80ba2             0.000000                    0.0  \n",
       "c016c6b0efa5             3.847321                    0.0  \n",
       "ba7f733a4f75             4.113780                    0.0  \n",
       "fbcf2443ffb2             3.518610                    0.0  \n",
       "\n",
       "[5 rows x 20856 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, taking a look at X shows there are a LOT of zeros:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca5ed2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:15.965560Z",
     "iopub.status.busy": "2022-12-22T12:30:15.965164Z",
     "iopub.status.idle": "2022-12-22T12:30:16.446012Z",
     "shell.execute_reply": "2022-12-22T12:30:16.445069Z"
    },
    "papermill": {
     "duration": 0.4933,
     "end_time": "2022-12-22T12:30:16.448712",
     "exception": false,
     "start_time": "2022-12-22T12:30:15.955412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119651, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first delete the X, X_test, Xt, and Y to save space\n",
    "del X\n",
    "del X_test\n",
    "del Xt\n",
    "del Y\n",
    "\n",
    "# load in the metadata since it'll be modified as well in the next cell\n",
    "# (Since X and Y are modified, it is convenient to modify the metadata to match\n",
    "# at the same time)\n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"] # focus on citeseq right now\n",
    "metadata_df.shape # show the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4a44ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:30:16.466889Z",
     "iopub.status.busy": "2022-12-22T12:30:16.466531Z",
     "iopub.status.idle": "2022-12-22T12:32:53.421465Z",
     "shell.execute_reply": "2022-12-22T12:32:53.420096Z"
    },
    "papermill": {
     "duration": 156.967078,
     "end_time": "2022-12-22T12:32:53.424026",
     "exception": false,
     "start_time": "2022-12-22T12:30:16.456948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (70988, 20856) 5.515 GByte\n",
      "Original Xt shape: (48663, 20856) 3.781 GByte\n",
      "CPU times: user 1min 56s, sys: 11.9 s, total: 2min 8s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 17s\n",
    "\n",
    "# Now, the data will be converted into sparse matrices\n",
    "# (See MSCI CITEseq Keras Quickstart by AMBROSM)\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "print(f\"Original X shape: {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "X = scipy.sparse.csr_matrix(X.values)\n",
    "gc.collect()\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "print(f\"Original Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "Xt = scipy.sparse.csr_matrix(Xt.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6479e6",
   "metadata": {
    "papermill": {
     "duration": 0.008402,
     "end_time": "2022-12-22T12:32:53.441138",
     "exception": false,
     "start_time": "2022-12-22T12:32:53.432736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform SVD\n",
    "Now perform SVD in order to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f806ad3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:32:53.460845Z",
     "iopub.status.busy": "2022-12-22T12:32:53.460448Z",
     "iopub.status.idle": "2022-12-22T12:36:52.901992Z",
     "shell.execute_reply": "2022-12-22T12:36:52.900691Z"
    },
    "papermill": {
     "duration": 239.465263,
     "end_time": "2022-12-22T12:36:52.915320",
     "exception": false,
     "start_time": "2022-12-22T12:32:53.450057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (119651, 20856)\n",
      "Shape of both after SVD:  (119651, 64)\n",
      "Reduced X shape:  (70988, 208)   0.055 GByte\n",
      "Reduced Xt shape: (48663, 208)   0.038 GByte\n",
      "CPU times: user 4min, sys: 4.81 s, total: 4min 5s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5-6 minutes\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "assert both.shape[0] == 119651\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n",
    "svd = TruncatedSVD(n_components=svd_ncount, random_state=1) # 512 is possible\n",
    "both = svd.fit_transform(both)\n",
    "print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:70988]\n",
    "Xt = both[70988:]\n",
    "del both\n",
    "X = np.hstack([X, X0])\n",
    "Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a192f5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:52.935628Z",
     "iopub.status.busy": "2022-12-22T12:36:52.934983Z",
     "iopub.status.idle": "2022-12-22T12:36:52.940125Z",
     "shell.execute_reply": "2022-12-22T12:36:52.939334Z"
    },
    "papermill": {
     "duration": 0.017467,
     "end_time": "2022-12-22T12:36:52.942086",
     "exception": false,
     "start_time": "2022-12-22T12:36:52.924619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:\n",
      "0.1390541\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\")\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3942667a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:52.961040Z",
     "iopub.status.busy": "2022-12-22T12:36:52.960216Z",
     "iopub.status.idle": "2022-12-22T12:36:53.566951Z",
     "shell.execute_reply": "2022-12-22T12:36:53.565739Z"
    },
    "papermill": {
     "duration": 0.618972,
     "end_time": "2022-12-22T12:36:53.569579",
     "exception": false,
     "start_time": "2022-12-22T12:36:52.950607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (70988, 140)   0.037 GByte\n"
     ]
    }
   ],
   "source": [
    "# Read Y\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "y_columns = list(Y.columns)\n",
    "Y = Y.values\n",
    "\n",
    "# Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# and negative_correlation_loss depends on it\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0248a",
   "metadata": {
    "papermill": {
     "duration": 0.008597,
     "end_time": "2022-12-22T12:36:53.587168",
     "exception": false,
     "start_time": "2022-12-22T12:36:53.578571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CITEseq learning model\n",
    "\n",
    "From: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f296040e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:53.607216Z",
     "iopub.status.busy": "2022-12-22T12:36:53.606456Z",
     "iopub.status.idle": "2022-12-22T12:36:59.041803Z",
     "shell.execute_reply": "2022-12-22T12:36:59.040461Z"
    },
    "papermill": {
     "duration": 5.448275,
     "end_time": "2022-12-22T12:36:59.044595",
     "exception": false,
     "start_time": "2022-12-22T12:36:53.596320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2886c",
   "metadata": {
    "papermill": {
     "duration": 0.008906,
     "end_time": "2022-12-22T12:36:59.062376",
     "exception": false,
     "start_time": "2022-12-22T12:36:59.053470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metric and loss function from MSCI CITEseq Keras Quickstart by AMBROSM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3910b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:59.081805Z",
     "iopub.status.busy": "2022-12-22T12:36:59.081134Z",
     "iopub.status.idle": "2022-12-22T12:36:59.090985Z",
     "shell.execute_reply": "2022-12-22T12:36:59.089947Z"
    },
    "papermill": {
     "duration": 0.02203,
     "end_time": "2022-12-22T12:36:59.093141",
     "exception": false,
     "start_time": "2022-12-22T12:36:59.071111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2387b8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:59.112440Z",
     "iopub.status.busy": "2022-12-22T12:36:59.111736Z",
     "iopub.status.idle": "2022-12-22T12:36:59.121343Z",
     "shell.execute_reply": "2022-12-22T12:36:59.120308Z"
    },
    "papermill": {
     "duration": 0.022016,
     "end_time": "2022-12-22T12:36:59.123802",
     "exception": false,
     "start_time": "2022-12-22T12:36:59.101786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(256, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1) \n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2)\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415a2d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:36:59.143101Z",
     "iopub.status.busy": "2022-12-22T12:36:59.142693Z",
     "iopub.status.idle": "2022-12-22T12:46:59.323523Z",
     "shell.execute_reply": "2022-12-22T12:46:59.322254Z"
    },
    "papermill": {
     "duration": 600.193598,
     "end_time": "2022-12-22T12:46:59.326329",
     "exception": false,
     "start_time": "2022-12-22T12:36:59.132731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:36:59.420375: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-22 12:36:59.649093: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 5s 43ms/step - loss: -0.8195 - negative_correlation_loss: -0.8361 - val_loss: -0.8522 - val_negative_correlation_loss: -0.8651\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8741 - negative_correlation_loss: -0.8850 - val_loss: -0.8690 - val_negative_correlation_loss: -0.8776\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 4s 41ms/step - loss: -0.8857 - negative_correlation_loss: -0.8931 - val_loss: -0.8727 - val_negative_correlation_loss: -0.8789\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8902 - negative_correlation_loss: -0.8963 - val_loss: -0.8778 - val_negative_correlation_loss: -0.8831\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8930 - negative_correlation_loss: -0.8984 - val_loss: -0.8799 - val_negative_correlation_loss: -0.8848\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8949 - negative_correlation_loss: -0.8998 - val_loss: -0.8808 - val_negative_correlation_loss: -0.8851\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8955 - negative_correlation_loss: -0.9001 - val_loss: -0.8797 - val_negative_correlation_loss: -0.8839\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8963 - negative_correlation_loss: -0.9007 - val_loss: -0.8820 - val_negative_correlation_loss: -0.8860\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.8971 - negative_correlation_loss: -0.9013 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8875\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8976 - negative_correlation_loss: -0.9016 - val_loss: -0.8824 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8978 - negative_correlation_loss: -0.9016 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8874\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8980 - negative_correlation_loss: -0.9018 - val_loss: -0.8823 - val_negative_correlation_loss: -0.8859\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8981 - negative_correlation_loss: -0.9020 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8853\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8987 - negative_correlation_loss: -0.9022 - val_loss: -0.8843 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8987 - negative_correlation_loss: -0.9024 - val_loss: -0.8827 - val_negative_correlation_loss: -0.8860\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8795 - val_negative_correlation_loss: -0.8829\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8833 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8991 - negative_correlation_loss: -0.9026 - val_loss: -0.8836 - val_negative_correlation_loss: -0.8869\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8992 - negative_correlation_loss: -0.9028 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8995 - negative_correlation_loss: -0.9030 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8995 - negative_correlation_loss: -0.9030 - val_loss: -0.8843 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8997 - negative_correlation_loss: -0.9031 - val_loss: -0.8838 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8996 - negative_correlation_loss: -0.9030 - val_loss: -0.8842 - val_negative_correlation_loss: -0.8874\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.8998 - negative_correlation_loss: -0.9032 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9001 - negative_correlation_loss: -0.9033 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 4s 49ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.8999 - negative_correlation_loss: -0.9033 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9000 - negative_correlation_loss: -0.9033 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9001 - negative_correlation_loss: -0.9035 - val_loss: -0.8863 - val_negative_correlation_loss: -0.8893\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9003 - negative_correlation_loss: -0.9036 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9003 - negative_correlation_loss: -0.9035 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 4s 41ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8887\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9007 - negative_correlation_loss: -0.9039 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8874\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9010 - negative_correlation_loss: -0.9042 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9007 - negative_correlation_loss: -0.9039 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9009 - negative_correlation_loss: -0.9040 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8895\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9010 - negative_correlation_loss: -0.9041 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9012 - negative_correlation_loss: -0.9041 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9009 - negative_correlation_loss: -0.9039 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9011 - negative_correlation_loss: -0.9041 - val_loss: -0.8839 - val_negative_correlation_loss: -0.8868\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9013 - negative_correlation_loss: -0.9041 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: -0.9015 - negative_correlation_loss: -0.9044 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: -0.9013 - negative_correlation_loss: -0.9042 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 4s 41ms/step - loss: -0.9015 - negative_correlation_loss: -0.9043 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 4s 40ms/step - loss: -0.9015 - negative_correlation_loss: -0.9044 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8880\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 4s 39ms/step - loss: -0.9017 - negative_correlation_loss: -0.9046 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 12:40:08.672830: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Fold 0, correlation =  0.88974\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 5s 42ms/step - loss: -0.8065 - negative_correlation_loss: -0.8228 - val_loss: -0.8454 - val_negative_correlation_loss: -0.8583\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8555 - negative_correlation_loss: -0.8659 - val_loss: -0.8691 - val_negative_correlation_loss: -0.8781\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8766 - negative_correlation_loss: -0.8843 - val_loss: -0.8777 - val_negative_correlation_loss: -0.8846\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8841 - negative_correlation_loss: -0.8902 - val_loss: -0.8821 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: -0.8877 - negative_correlation_loss: -0.8932 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8902 - negative_correlation_loss: -0.8955 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8913 - negative_correlation_loss: -0.8963 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8918\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8924 - negative_correlation_loss: -0.8971 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8912\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8930 - negative_correlation_loss: -0.8975 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8915\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8936 - negative_correlation_loss: -0.8980 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8922\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8937 - negative_correlation_loss: -0.8980 - val_loss: -0.8890 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8940 - negative_correlation_loss: -0.8982 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8924\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8947 - negative_correlation_loss: -0.8988 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8948 - negative_correlation_loss: -0.8988 - val_loss: -0.8898 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8950 - negative_correlation_loss: -0.8990 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8952 - negative_correlation_loss: -0.8991 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8933\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8952 - negative_correlation_loss: -0.8992 - val_loss: -0.8896 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8951 - negative_correlation_loss: -0.8991 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8919\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: -0.8957 - negative_correlation_loss: -0.8996 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8881 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8958 - negative_correlation_loss: -0.8996 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 4s 49ms/step - loss: -0.8964 - negative_correlation_loss: -0.9001 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8964 - negative_correlation_loss: -0.9000 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8964 - negative_correlation_loss: -0.8999 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8962 - negative_correlation_loss: -0.8999 - val_loss: -0.8889 - val_negative_correlation_loss: -0.8925\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8964 - negative_correlation_loss: -0.9000 - val_loss: -0.8884 - val_negative_correlation_loss: -0.8920\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8967 - negative_correlation_loss: -0.9002 - val_loss: -0.8914 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8970 - negative_correlation_loss: -0.9005 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8892 - val_negative_correlation_loss: -0.8928\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8900 - val_negative_correlation_loss: -0.8934\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8970 - negative_correlation_loss: -0.9004 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8941\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8971 - negative_correlation_loss: -0.9005 - val_loss: -0.8912 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8906 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8936\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8975 - negative_correlation_loss: -0.9008 - val_loss: -0.8916 - val_negative_correlation_loss: -0.8948\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8977 - negative_correlation_loss: -0.9009 - val_loss: -0.8906 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8976 - negative_correlation_loss: -0.9008 - val_loss: -0.8910 - val_negative_correlation_loss: -0.8942\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 4s 48ms/step - loss: -0.8976 - negative_correlation_loss: -0.9009 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8941\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 4s 41ms/step - loss: -0.8977 - negative_correlation_loss: -0.9009 - val_loss: -0.8911 - val_negative_correlation_loss: -0.8943\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8979 - negative_correlation_loss: -0.9011 - val_loss: -0.8923 - val_negative_correlation_loss: -0.8955\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8981 - negative_correlation_loss: -0.9012 - val_loss: -0.8915 - val_negative_correlation_loss: -0.8946\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 4s 39ms/step - loss: -0.8980 - negative_correlation_loss: -0.9011 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8913 - val_negative_correlation_loss: -0.8944\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 4s 40ms/step - loss: -0.8982 - negative_correlation_loss: -0.9013 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 4s 47ms/step - loss: -0.8983 - negative_correlation_loss: -0.9014 - val_loss: -0.8917 - val_negative_correlation_loss: -0.8947\n",
      "model saved\n",
      "Fold 1, correlation =  0.89549\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 5s 41ms/step - loss: -0.8035 - negative_correlation_loss: -0.8195 - val_loss: -0.8396 - val_negative_correlation_loss: -0.8517\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8628 - negative_correlation_loss: -0.8729 - val_loss: -0.8676 - val_negative_correlation_loss: -0.8758\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8778 - negative_correlation_loss: -0.8850 - val_loss: -0.8753 - val_negative_correlation_loss: -0.8816\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8853 - negative_correlation_loss: -0.8910 - val_loss: -0.8810 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8893 - negative_correlation_loss: -0.8944 - val_loss: -0.8813 - val_negative_correlation_loss: -0.8861\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8910 - negative_correlation_loss: -0.8958 - val_loss: -0.8840 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8921 - negative_correlation_loss: -0.8967 - val_loss: -0.8834 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8929 - negative_correlation_loss: -0.8973 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8933 - negative_correlation_loss: -0.8975 - val_loss: -0.8825 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8938 - negative_correlation_loss: -0.8979 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8942 - negative_correlation_loss: -0.8982 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8943 - negative_correlation_loss: -0.8983 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8945 - negative_correlation_loss: -0.8984 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8892\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8948 - negative_correlation_loss: -0.8987 - val_loss: -0.8834 - val_negative_correlation_loss: -0.8872\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8949 - negative_correlation_loss: -0.8988 - val_loss: -0.8852 - val_negative_correlation_loss: -0.8888\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8950 - negative_correlation_loss: -0.8987 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8882\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8954 - negative_correlation_loss: -0.8992 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8954 - negative_correlation_loss: -0.8991 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8957 - negative_correlation_loss: -0.8993 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8957 - negative_correlation_loss: -0.8992 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8959 - negative_correlation_loss: -0.8995 - val_loss: -0.8856 - val_negative_correlation_loss: -0.8890\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8962 - negative_correlation_loss: -0.8996 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 4s 42ms/step - loss: -0.8965 - negative_correlation_loss: -0.8998 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8965 - negative_correlation_loss: -0.8998 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8966 - negative_correlation_loss: -0.9000 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8895\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8968 - negative_correlation_loss: -0.9000 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8968 - negative_correlation_loss: -0.9000 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: -0.8970 - negative_correlation_loss: -0.9002 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8971 - negative_correlation_loss: -0.9003 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8896\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8972 - negative_correlation_loss: -0.9004 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8971 - negative_correlation_loss: -0.9003 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8972 - negative_correlation_loss: -0.9005 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8905\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8975 - negative_correlation_loss: -0.9007 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8976 - negative_correlation_loss: -0.9007 - val_loss: -0.8877 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: -0.8976 - negative_correlation_loss: -0.9007 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8977 - negative_correlation_loss: -0.9007 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8977 - negative_correlation_loss: -0.9006 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8898\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 4s 42ms/step - loss: -0.8980 - negative_correlation_loss: -0.9009 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8980 - negative_correlation_loss: -0.9008 - val_loss: -0.8889 - val_negative_correlation_loss: -0.8917\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8980 - negative_correlation_loss: -0.9009 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8909\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8980 - negative_correlation_loss: -0.9010 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8901\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 5s 48ms/step - loss: -0.8980 - negative_correlation_loss: -0.9010 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8981 - negative_correlation_loss: -0.9010 - val_loss: -0.8888 - val_negative_correlation_loss: -0.8916\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8982 - negative_correlation_loss: -0.9010 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 4s 39ms/step - loss: -0.8983 - negative_correlation_loss: -0.9011 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 4s 40ms/step - loss: -0.8983 - negative_correlation_loss: -0.9012 - val_loss: -0.8882 - val_negative_correlation_loss: -0.8910\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 4s 41ms/step - loss: -0.8984 - negative_correlation_loss: -0.9013 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8898\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "model saved\n",
      "Fold 2, correlation =  0.89181\n",
      "\u001b[32m\u001b[1mMean corr = 0.89234\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89233\u001b[0m\n",
      "CPU times: user 26min 11s, sys: 52.8 s, total: 27min 4s\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 13 min 44 s\n",
    "VERBOSE = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 50 \n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 40, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"min\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [\n",
    "                    lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22443d27",
   "metadata": {
    "papermill": {
     "duration": 0.524929,
     "end_time": "2022-12-22T12:47:00.315317",
     "exception": false,
     "start_time": "2022-12-22T12:46:59.790388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b1c2aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:47:01.235672Z",
     "iopub.status.busy": "2022-12-22T12:47:01.234699Z",
     "iopub.status.idle": "2022-12-22T12:47:12.167255Z",
     "shell.execute_reply": "2022-12-22T12:47:12.165675Z"
    },
    "papermill": {
     "duration": 11.396462,
     "end_time": "2022-12-22T12:47:12.169950",
     "exception": false,
     "start_time": "2022-12-22T12:47:00.773488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "Predicting with fold 1\n",
      "Predicting with fold 2\n",
      "CPU times: user 15.7 s, sys: 2.04 s, total: 17.7 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Around 20 s\n",
    "\n",
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98cb76",
   "metadata": {
    "papermill": {
     "duration": 0.53714,
     "end_time": "2022-12-22T12:47:13.179926",
     "exception": false,
     "start_time": "2022-12-22T12:47:12.642786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save submission by merging with multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56815811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T12:47:14.118969Z",
     "iopub.status.busy": "2022-12-22T12:47:14.118538Z",
     "iopub.status.idle": "2022-12-22T12:50:49.351029Z",
     "shell.execute_reply": "2022-12-22T12:50:49.349687Z"
    },
    "papermill": {
     "duration": 216.242548,
     "end_time": "2022-12-22T12:50:49.890914",
     "exception": false,
     "start_time": "2022-12-22T12:47:13.648366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0          -276.658997\n",
       "1          -261.586487\n",
       "2          -226.882538\n",
       "3           193.443710\n",
       "4           284.802704\n",
       "               ...    \n",
       "65744175      7.207031\n",
       "65744176      0.047058\n",
       "65744177      0.053619\n",
       "65744178      1.371094\n",
       "65744179      6.566406\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 11s, sys: 13.2 s, total: 3min 24s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 41s\n",
    "\n",
    "# Merge with multiome\n",
    "submission = pd.read_csv(multi_ome_only_file,index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_full_m64_c64.csv')\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1348.929282,
   "end_time": "2022-12-22T12:50:53.515680",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-22T12:28:24.586398",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
