{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e322db8",
   "metadata": {
    "papermill": {
     "duration": 0.007685,
     "end_time": "2022-12-22T14:45:40.695066",
     "exception": false,
     "start_time": "2022-12-22T14:45:40.687381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Because the datasets are SO large (especially the Multiome dataset), instead of running both parts of the project in one notebook (and risk Kaggle running out of storage space then resetting all progress), it is more convenient to separate the multiome and citeseq parts of the project, then later merge the predicted outputs from the two parts together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19323aac",
   "metadata": {
    "papermill": {
     "duration": 0.006261,
     "end_time": "2022-12-22T14:45:40.708124",
     "exception": false,
     "start_time": "2022-12-22T14:45:40.701863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook concerns itself with the CITEseq portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756898e",
   "metadata": {
    "papermill": {
     "duration": 0.006231,
     "end_time": "2022-12-22T14:45:40.720918",
     "exception": false,
     "start_time": "2022-12-22T14:45:40.714687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First, all the basic imports and file names which may or may not be used is loaded in essentially as a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1c6c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:45:40.736219Z",
     "iopub.status.busy": "2022-12-22T14:45:40.735792Z",
     "iopub.status.idle": "2022-12-22T14:45:52.302223Z",
     "shell.execute_reply": "2022-12-22T14:45:52.300924Z"
    },
    "papermill": {
     "duration": 11.577126,
     "end_time": "2022-12-22T14:45:52.304684",
     "exception": false,
     "start_time": "2022-12-22T14:45:40.727558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/conda/lib/python3.7/site-packages (3.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from tables) (1.21.6)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tables) (21.3)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.7/site-packages (from tables) (2.8.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tables) (3.0.9)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f03314",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-22T14:45:52.320294Z",
     "iopub.status.busy": "2022-12-22T14:45:52.319930Z",
     "iopub.status.idle": "2022-12-22T14:45:53.917088Z",
     "shell.execute_reply": "2022-12-22T14:45:53.915776Z"
    },
    "papermill": {
     "duration": 1.607801,
     "end_time": "2022-12-22T14:45:53.919727",
     "exception": false,
     "start_time": "2022-12-22T14:45:52.311926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, datetime, scipy.sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb95180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:45:53.936071Z",
     "iopub.status.busy": "2022-12-22T14:45:53.935730Z",
     "iopub.status.idle": "2022-12-22T14:45:53.945305Z",
     "shell.execute_reply": "2022-12-22T14:45:53.943113Z"
    },
    "papermill": {
     "duration": 0.020258,
     "end_time": "2022-12-22T14:45:53.947866",
     "exception": false,
     "start_time": "2022-12-22T14:45:53.927608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory of the data\n",
    "DATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "FP_MULT_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "FP_MULT_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "FP_MULT_TRAIN_TARGETS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\"\n",
    "FP_MULT_TRAIN_TARGETS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TRAIN_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\"\n",
    "FP_MULT_TEST_INPUTS_idx = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\"\n",
    "FP_MULT_TEST_INPUTS_sparse = \"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\"\n",
    "\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n",
    "\n",
    "FP_EVALUATION_IDS_parquet = \"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\"\n",
    "\n",
    "multi_ome_only_file = '../input/n256-nb2-multiome/multiome_only_256.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38087a51",
   "metadata": {
    "papermill": {
     "duration": 0.00659,
     "end_time": "2022-12-22T14:45:53.961499",
     "exception": false,
     "start_time": "2022-12-22T14:45:53.954909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CITEseq Part: Predicting protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc293c76",
   "metadata": {
    "papermill": {
     "duration": 0.006562,
     "end_time": "2022-12-22T14:45:53.974967",
     "exception": false,
     "start_time": "2022-12-22T14:45:53.968405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the CITEseq portion begins\n",
    "\n",
    "\n",
    "Code from pourchot: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4188fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:45:53.990677Z",
     "iopub.status.busy": "2022-12-22T14:45:53.990345Z",
     "iopub.status.idle": "2022-12-22T14:45:53.996253Z",
     "shell.execute_reply": "2022-12-22T14:45:53.994746Z"
    },
    "papermill": {
     "duration": 0.016701,
     "end_time": "2022-12-22T14:45:53.998678",
     "exception": false,
     "start_time": "2022-12-22T14:45:53.981977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_ncount = 64 # amount of dimensions to keep for SVD later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbf23e",
   "metadata": {
    "papermill": {
     "duration": 0.006551,
     "end_time": "2022-12-22T14:45:54.012672",
     "exception": false,
     "start_time": "2022-12-22T14:45:54.006121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1c6daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:45:54.027717Z",
     "iopub.status.busy": "2022-12-22T14:45:54.027120Z",
     "iopub.status.idle": "2022-12-22T14:47:11.663719Z",
     "shell.execute_reply": "2022-12-22T14:47:11.662021Z"
    },
    "papermill": {
     "duration": 77.647346,
     "end_time": "2022-12-22T14:47:11.666784",
     "exception": false,
     "start_time": "2022-12-22T14:45:54.019438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "\n",
    "# Load test inputs\n",
    "X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e554de6",
   "metadata": {
    "papermill": {
     "duration": 0.007117,
     "end_time": "2022-12-22T14:47:11.681275",
     "exception": false,
     "start_time": "2022-12-22T14:47:11.674158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Constant columns (a.k.a. columns that have the same value in all rows) are useless for machine learning. Just like if you are told to differentiate between apples and oranges, and there is a column which indicates whether apples and oranges are fruits and vegetables, both the apples and oranges will be \"fruit,\" which informs you nothing about the difference between apples and oranges.\n",
    "\n",
    "Hence, constant columns found in the training inputs are found in order to be removed from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a4631c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:11.697967Z",
     "iopub.status.busy": "2022-12-22T14:47:11.697626Z",
     "iopub.status.idle": "2022-12-22T14:47:13.742426Z",
     "shell.execute_reply": "2022-12-22T14:47:13.740562Z"
    },
    "papermill": {
     "duration": 2.055812,
     "end_time": "2022-12-22T14:47:13.744729",
     "exception": false,
     "start_time": "2022-12-22T14:47:11.688917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant columns  1194\n"
     ]
    }
   ],
   "source": [
    "constant_cols = list(X.columns[(X == 0).all(axis=0).values]) +\\\n",
    "                list(X_test.columns[(X_test == 0).all(axis=0).values])\n",
    "print('constant columns ',len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335ef329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:13.761126Z",
     "iopub.status.busy": "2022-12-22T14:47:13.760773Z",
     "iopub.status.idle": "2022-12-22T14:47:15.445889Z",
     "shell.execute_reply": "2022-12-22T14:47:15.444456Z"
    },
    "papermill": {
     "duration": 1.69617,
     "end_time": "2022-12-22T14:47:15.448222",
     "exception": false,
     "start_time": "2022-12-22T14:47:13.752052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the constant columns from the training data\n",
    "X = X.drop(columns = constant_cols)\n",
    "Xt = X_test.drop(columns = constant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cebf25",
   "metadata": {
    "papermill": {
     "duration": 0.00705,
     "end_time": "2022-12-22T14:47:15.462030",
     "exception": false,
     "start_time": "2022-12-22T14:47:15.454980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The \"important columns\" are columns that appear as training targets. Hence, it is considered important to keep them in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038a76ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:15.478214Z",
     "iopub.status.busy": "2022-12-22T14:47:15.477808Z",
     "iopub.status.idle": "2022-12-22T14:47:15.836473Z",
     "shell.execute_reply": "2022-12-22T14:47:15.834978Z"
    },
    "papermill": {
     "duration": 0.369243,
     "end_time": "2022-12-22T14:47:15.838629",
     "exception": false,
     "start_time": "2022-12-22T14:47:15.469386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important columns  144\n"
     ]
    }
   ],
   "source": [
    "important_cols = []\n",
    "for y_col in Y.columns:\n",
    "    important_cols += [x_col for x_col in X.columns if y_col in x_col]\n",
    "print('important columns ',len(important_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170aece",
   "metadata": {
    "papermill": {
     "duration": 0.006655,
     "end_time": "2022-12-22T14:47:15.852293",
     "exception": false,
     "start_time": "2022-12-22T14:47:15.845638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before this point, the training and testing data has been loaded in order to determine the constant columns. The training and testing data will be loaded now as sparse matrices with the constant columns removed and the important columns kept. The purpose of sparse matrices is to efficiently store data with lots of zeros and also speed up the machine learning processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "546e8296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:15.867604Z",
     "iopub.status.busy": "2022-12-22T14:47:15.867273Z",
     "iopub.status.idle": "2022-12-22T14:47:15.907200Z",
     "shell.execute_reply": "2022-12-22T14:47:15.905765Z"
    },
    "papermill": {
     "duration": 0.050281,
     "end_time": "2022-12-22T14:47:15.909262",
     "exception": false,
     "start_time": "2022-12-22T14:47:15.858981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>ENSG00000121410_A1BG</th>\n",
       "      <th>ENSG00000268895_A1BG-AS1</th>\n",
       "      <th>ENSG00000175899_A2M</th>\n",
       "      <th>ENSG00000245105_A2M-AS1</th>\n",
       "      <th>ENSG00000128274_A4GALT</th>\n",
       "      <th>ENSG00000094914_AAAS</th>\n",
       "      <th>ENSG00000081760_AACS</th>\n",
       "      <th>ENSG00000109576_AADAT</th>\n",
       "      <th>ENSG00000103591_AAGAB</th>\n",
       "      <th>ENSG00000115977_AAK1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000153975_ZUP1</th>\n",
       "      <th>ENSG00000086827_ZW10</th>\n",
       "      <th>ENSG00000174442_ZWILCH</th>\n",
       "      <th>ENSG00000122952_ZWINT</th>\n",
       "      <th>ENSG00000198205_ZXDA</th>\n",
       "      <th>ENSG00000198455_ZXDB</th>\n",
       "      <th>ENSG00000070476_ZXDC</th>\n",
       "      <th>ENSG00000162378_ZYG11B</th>\n",
       "      <th>ENSG00000159840_ZYX</th>\n",
       "      <th>ENSG00000074755_ZZEF1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45006fe3e4c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.090185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02759a80ba2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.039545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c016c6b0efa5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>4.529743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>3.847321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba7f733a4f75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.513782</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>5.020215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.436846</td>\n",
       "      <td>4.113780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbcf2443ffb2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51861</td>\n",
       "      <td>4.196826</td>\n",
       "      <td>3.518610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id       ENSG00000121410_A1BG  ENSG00000268895_A1BG-AS1  \\\n",
       "cell_id                                                        \n",
       "45006fe3e4c8                   0.0                       0.0   \n",
       "d02759a80ba2                   0.0                       0.0   \n",
       "c016c6b0efa5                   0.0                       0.0   \n",
       "ba7f733a4f75                   0.0                       0.0   \n",
       "fbcf2443ffb2                   0.0                       0.0   \n",
       "\n",
       "gene_id       ENSG00000175899_A2M  ENSG00000245105_A2M-AS1  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                  0.0                      0.0   \n",
       "d02759a80ba2                  0.0                      0.0   \n",
       "c016c6b0efa5                  0.0                      0.0   \n",
       "ba7f733a4f75                  0.0                      0.0   \n",
       "fbcf2443ffb2                  0.0                      0.0   \n",
       "\n",
       "gene_id       ENSG00000128274_A4GALT  ENSG00000094914_AAAS  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8                0.000000              0.000000   \n",
       "d02759a80ba2                0.000000              0.000000   \n",
       "c016c6b0efa5                3.847321              0.000000   \n",
       "ba7f733a4f75                0.000000              3.436846   \n",
       "fbcf2443ffb2                0.000000              0.000000   \n",
       "\n",
       "gene_id       ENSG00000081760_AACS  ENSG00000109576_AADAT  \\\n",
       "cell_id                                                     \n",
       "45006fe3e4c8              0.000000               0.000000   \n",
       "d02759a80ba2              0.000000               0.000000   \n",
       "c016c6b0efa5              3.847321               3.847321   \n",
       "ba7f733a4f75              3.436846               0.000000   \n",
       "fbcf2443ffb2              4.196826               0.000000   \n",
       "\n",
       "gene_id       ENSG00000103591_AAGAB  ENSG00000115977_AAK1  ...  \\\n",
       "cell_id                                                    ...   \n",
       "45006fe3e4c8                    0.0              0.000000  ...   \n",
       "d02759a80ba2                    0.0              4.039545  ...   \n",
       "c016c6b0efa5                    0.0              0.000000  ...   \n",
       "ba7f733a4f75                    0.0              4.513782  ...   \n",
       "fbcf2443ffb2                    0.0              0.000000  ...   \n",
       "\n",
       "gene_id       ENSG00000153975_ZUP1  ENSG00000086827_ZW10  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8              0.000000              0.000000   \n",
       "d02759a80ba2              0.000000              0.000000   \n",
       "c016c6b0efa5              0.000000              0.000000   \n",
       "ba7f733a4f75              3.436846              0.000000   \n",
       "fbcf2443ffb2              0.000000              4.196826   \n",
       "\n",
       "gene_id       ENSG00000174442_ZWILCH  ENSG00000122952_ZWINT  \\\n",
       "cell_id                                                       \n",
       "45006fe3e4c8                0.000000               0.000000   \n",
       "d02759a80ba2                0.000000               4.039545   \n",
       "c016c6b0efa5                3.847321               4.529743   \n",
       "ba7f733a4f75                4.113780               5.020215   \n",
       "fbcf2443ffb2                4.196826               4.196826   \n",
       "\n",
       "gene_id       ENSG00000198205_ZXDA  ENSG00000198455_ZXDB  \\\n",
       "cell_id                                                    \n",
       "45006fe3e4c8                   0.0                   0.0   \n",
       "d02759a80ba2                   0.0                   0.0   \n",
       "c016c6b0efa5                   0.0                   0.0   \n",
       "ba7f733a4f75                   0.0                   0.0   \n",
       "fbcf2443ffb2                   0.0                   0.0   \n",
       "\n",
       "gene_id       ENSG00000070476_ZXDC  ENSG00000162378_ZYG11B  \\\n",
       "cell_id                                                      \n",
       "45006fe3e4c8               0.00000                0.000000   \n",
       "d02759a80ba2               0.00000                0.000000   \n",
       "c016c6b0efa5               0.00000                3.847321   \n",
       "ba7f733a4f75               0.00000                3.436846   \n",
       "fbcf2443ffb2               3.51861                4.196826   \n",
       "\n",
       "gene_id       ENSG00000159840_ZYX  ENSG00000074755_ZZEF1  \n",
       "cell_id                                                   \n",
       "45006fe3e4c8             4.090185                    0.0  \n",
       "d02759a80ba2             0.000000                    0.0  \n",
       "c016c6b0efa5             3.847321                    0.0  \n",
       "ba7f733a4f75             4.113780                    0.0  \n",
       "fbcf2443ffb2             3.518610                    0.0  \n",
       "\n",
       "[5 rows x 20856 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, taking a look at X shows there are a LOT of zeros:\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4738120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:15.925531Z",
     "iopub.status.busy": "2022-12-22T14:47:15.925232Z",
     "iopub.status.idle": "2022-12-22T14:47:16.348474Z",
     "shell.execute_reply": "2022-12-22T14:47:16.347333Z"
    },
    "papermill": {
     "duration": 0.434828,
     "end_time": "2022-12-22T14:47:16.351475",
     "exception": false,
     "start_time": "2022-12-22T14:47:15.916647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119651, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first delete the X, X_test, Xt, and Y to save space\n",
    "del X\n",
    "del X_test\n",
    "del Xt\n",
    "del Y\n",
    "\n",
    "# load in the metadata since it'll be modified as well in the next cell\n",
    "# (Since X and Y are modified, it is convenient to modify the metadata to match\n",
    "# at the same time)\n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"] # focus on citeseq right now\n",
    "metadata_df.shape # show the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26171f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:47:16.367836Z",
     "iopub.status.busy": "2022-12-22T14:47:16.367489Z",
     "iopub.status.idle": "2022-12-22T14:49:28.819227Z",
     "shell.execute_reply": "2022-12-22T14:49:28.818074Z"
    },
    "papermill": {
     "duration": 132.462172,
     "end_time": "2022-12-22T14:49:28.820999",
     "exception": false,
     "start_time": "2022-12-22T14:47:16.358827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (70988, 20856) 5.515 GByte\n",
      "Original Xt shape: (48663, 20856) 3.781 GByte\n",
      "CPU times: user 1min 28s, sys: 7.81 s, total: 1min 36s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 17s\n",
    "\n",
    "# Now, the data will be converted into sparse matrices\n",
    "# (See MSCI CITEseq Keras Quickstart by AMBROSM)\n",
    "\n",
    "# Read train and convert to sparse matrix\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "X0 = X[important_cols].values\n",
    "print(f\"Original X shape: {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "X = scipy.sparse.csr_matrix(X.values)\n",
    "gc.collect()\n",
    "\n",
    "# Read test and convert to sparse matrix\n",
    "Xt = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\n",
    "cell_index_test = Xt.index\n",
    "meta_test = metadata_df.reindex(cell_index_test)\n",
    "X0t = Xt[important_cols].values\n",
    "print(f\"Original Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "gc.collect()\n",
    "Xt = scipy.sparse.csr_matrix(Xt.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968797eb",
   "metadata": {
    "papermill": {
     "duration": 0.006677,
     "end_time": "2022-12-22T14:49:28.834642",
     "exception": false,
     "start_time": "2022-12-22T14:49:28.827965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform SVD\n",
    "Now perform SVD in order to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c649b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:49:28.851159Z",
     "iopub.status.busy": "2022-12-22T14:49:28.849731Z",
     "iopub.status.idle": "2022-12-22T14:52:24.836911Z",
     "shell.execute_reply": "2022-12-22T14:52:24.835478Z"
    },
    "papermill": {
     "duration": 176.002731,
     "end_time": "2022-12-22T14:52:24.844247",
     "exception": false,
     "start_time": "2022-12-22T14:49:28.841516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of both before SVD: (119651, 20856)\n",
      "Shape of both after SVD:  (119651, 64)\n",
      "Reduced X shape:  (70988, 208)   0.055 GByte\n",
      "Reduced Xt shape: (48663, 208)   0.038 GByte\n",
      "CPU times: user 2min 56s, sys: 5.45 s, total: 3min 1s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5-6 minutes\n",
    "\n",
    "# Apply the singular value decomposition\n",
    "both = scipy.sparse.vstack([X, Xt])\n",
    "assert both.shape[0] == 119651\n",
    "print(f\"Shape of both before SVD: {both.shape}\")\n",
    "svd = TruncatedSVD(n_components=svd_ncount, random_state=1) # 512 is possible\n",
    "both = svd.fit_transform(both)\n",
    "print(f\"Shape of both after SVD:  {both.shape}\")\n",
    "    \n",
    "# Hstack the svd output with the important features\n",
    "X = both[:70988]\n",
    "Xt = both[70988:]\n",
    "del both\n",
    "X = np.hstack([X, X0])\n",
    "Xt = np.hstack([Xt, X0t])\n",
    "print(f\"Reduced X shape:  {str(X.shape):14} {X.size*4/1024/1024/1024:2.3f} GByte\")\n",
    "print(f\"Reduced Xt shape: {str(Xt.shape):14} {Xt.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0a7d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:24.859456Z",
     "iopub.status.busy": "2022-12-22T14:52:24.859092Z",
     "iopub.status.idle": "2022-12-22T14:52:24.865750Z",
     "shell.execute_reply": "2022-12-22T14:52:24.864032Z"
    },
    "papermill": {
     "duration": 0.017418,
     "end_time": "2022-12-22T14:52:24.868508",
     "exception": false,
     "start_time": "2022-12-22T14:52:24.851090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:\n",
      "0.1390541\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\")\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58064eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:24.885938Z",
     "iopub.status.busy": "2022-12-22T14:52:24.885105Z",
     "iopub.status.idle": "2022-12-22T14:52:25.515857Z",
     "shell.execute_reply": "2022-12-22T14:52:25.514580Z"
    },
    "papermill": {
     "duration": 0.641309,
     "end_time": "2022-12-22T14:52:25.517639",
     "exception": false,
     "start_time": "2022-12-22T14:52:24.876330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (70988, 140)   0.037 GByte\n"
     ]
    }
   ],
   "source": [
    "# Read Y\n",
    "Y = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n",
    "y_columns = list(Y.columns)\n",
    "Y = Y.values\n",
    "\n",
    "# Normalize the targets row-wise: This doesn't change the correlations,\n",
    "# and negative_correlation_loss depends on it\n",
    "Y -= Y.mean(axis=1).reshape(-1, 1)\n",
    "Y /= Y.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "print(f\"Y shape: {str(Y.shape):14} {Y.size*4/1024/1024/1024:2.3f} GByte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72382c3",
   "metadata": {
    "papermill": {
     "duration": 0.006419,
     "end_time": "2022-12-22T14:52:25.531399",
     "exception": false,
     "start_time": "2022-12-22T14:52:25.524980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CITEseq learning model\n",
    "\n",
    "From: https://www.kaggle.com/code/pourchot/all-in-one-citeseq-multiome-with-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154c82fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:25.547845Z",
     "iopub.status.busy": "2022-12-22T14:52:25.546634Z",
     "iopub.status.idle": "2022-12-22T14:52:32.463314Z",
     "shell.execute_reply": "2022-12-22T14:52:32.462345Z"
    },
    "papermill": {
     "duration": 6.927359,
     "end_time": "2022-12-22T14:52:32.465626",
     "exception": false,
     "start_time": "2022-12-22T14:52:25.538267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd675adf",
   "metadata": {
    "papermill": {
     "duration": 0.006598,
     "end_time": "2022-12-22T14:52:32.479412",
     "exception": false,
     "start_time": "2022-12-22T14:52:32.472814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metric and loss function from MSCI CITEseq Keras Quickstart by AMBROSM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e72b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:32.495161Z",
     "iopub.status.busy": "2022-12-22T14:52:32.494559Z",
     "iopub.status.idle": "2022-12-22T14:52:32.503125Z",
     "shell.execute_reply": "2022-12-22T14:52:32.502238Z"
    },
    "papermill": {
     "duration": 0.019035,
     "end_time": "2022-12-22T14:52:32.505470",
     "exception": false,
     "start_time": "2022-12-22T14:52:32.486435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "def negative_correlation_loss(y_true, y_pred):\n",
    "    \"\"\"Negative correlation loss function for Keras\n",
    "    \n",
    "    Precondition:\n",
    "    y_true.mean(axis=1) == 0\n",
    "    y_true.std(axis=1) == 1\n",
    "    \n",
    "    Returns:\n",
    "    -1 = perfect positive correlation\n",
    "    1 = totally negative correlation\n",
    "    \"\"\"\n",
    "    my = K.mean(tf.convert_to_tensor(y_pred), axis=1)\n",
    "    my = tf.tile(tf.expand_dims(my, axis=1), (1, y_true.shape[1]))\n",
    "    ym = y_pred - my\n",
    "    r_num = K.sum(tf.multiply(y_true, ym), axis=1)\n",
    "    r_den = tf.sqrt(K.sum(K.square(ym), axis=1) * float(y_true.shape[-1]))\n",
    "    r = tf.reduce_mean(r_num / r_den)\n",
    "    return - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d949dfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:32.522096Z",
     "iopub.status.busy": "2022-12-22T14:52:32.521762Z",
     "iopub.status.idle": "2022-12-22T14:52:32.530757Z",
     "shell.execute_reply": "2022-12-22T14:52:32.529486Z"
    },
    "papermill": {
     "duration": 0.020111,
     "end_time": "2022-12-22T14:52:32.533211",
     "exception": false,
     "start_time": "2022-12-22T14:52:32.513100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 0.01\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    reg1 = 9.613e-06\n",
    "    reg2 = 1e-07\n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    DROP = 0.1\n",
    "\n",
    "    activation = 'selu'\n",
    "    inputs = Input(shape =(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(256, \n",
    "              kernel_regularizer = REG1,\n",
    "              activation = activation,\n",
    "             )(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    \n",
    "    \n",
    "    x1 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    \n",
    "    \n",
    "    x2 = Dense(512, \n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x1) \n",
    "    x2= Dropout(DROP)(x2)\n",
    "    \n",
    "    x3 = Dense(Y.shape[1],\n",
    "               kernel_regularizer = REG1,\n",
    "               activation = activation,\n",
    "             )(x2)\n",
    "    x3 = Dropout(DROP)(x3)\n",
    "\n",
    "         \n",
    "    x = Concatenate()([\n",
    "                x0, \n",
    "                x1, \n",
    "                x2, \n",
    "                x3\n",
    "                ])\n",
    "    \n",
    "    x = Dense(Y.shape[1], \n",
    "                kernel_regularizer = REG2,\n",
    "                activation='linear',\n",
    "                )(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2747ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T14:52:32.550141Z",
     "iopub.status.busy": "2022-12-22T14:52:32.549795Z",
     "iopub.status.idle": "2022-12-22T15:05:33.708137Z",
     "shell.execute_reply": "2022-12-22T15:05:33.706782Z"
    },
    "papermill": {
     "duration": 781.169243,
     "end_time": "2022-12-22T15:05:33.710086",
     "exception": false,
     "start_time": "2022-12-22T14:52:32.540843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 14:52:32.820435: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-22 14:52:33.027252: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 7s 61ms/step - loss: -0.8194 - negative_correlation_loss: -0.8360 - val_loss: -0.8517 - val_negative_correlation_loss: -0.8646\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8740 - negative_correlation_loss: -0.8849 - val_loss: -0.8692 - val_negative_correlation_loss: -0.8778\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8856 - negative_correlation_loss: -0.8931 - val_loss: -0.8729 - val_negative_correlation_loss: -0.8792\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8903 - negative_correlation_loss: -0.8963 - val_loss: -0.8776 - val_negative_correlation_loss: -0.8829\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8929 - negative_correlation_loss: -0.8983 - val_loss: -0.8798 - val_negative_correlation_loss: -0.8847\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8949 - negative_correlation_loss: -0.8997 - val_loss: -0.8811 - val_negative_correlation_loss: -0.8854\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8954 - negative_correlation_loss: -0.9001 - val_loss: -0.8804 - val_negative_correlation_loss: -0.8846\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 5s 58ms/step - loss: -0.8963 - negative_correlation_loss: -0.9007 - val_loss: -0.8823 - val_negative_correlation_loss: -0.8864\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8969 - negative_correlation_loss: -0.9011 - val_loss: -0.8833 - val_negative_correlation_loss: -0.8871\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8972 - negative_correlation_loss: -0.9013 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8975 - negative_correlation_loss: -0.9015 - val_loss: -0.8827 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8978 - negative_correlation_loss: -0.9017 - val_loss: -0.8836 - val_negative_correlation_loss: -0.8873\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8979 - negative_correlation_loss: -0.9018 - val_loss: -0.8828 - val_negative_correlation_loss: -0.8864\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.8982 - negative_correlation_loss: -0.9020 - val_loss: -0.8817 - val_negative_correlation_loss: -0.8853\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.8986 - negative_correlation_loss: -0.9022 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8987 - negative_correlation_loss: -0.9024 - val_loss: -0.8830 - val_negative_correlation_loss: -0.8863\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8988 - negative_correlation_loss: -0.9025 - val_loss: -0.8805 - val_negative_correlation_loss: -0.8839\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 4s 50ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8832 - val_negative_correlation_loss: -0.8866\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8989 - negative_correlation_loss: -0.9025 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8874\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8993 - negative_correlation_loss: -0.9028 - val_loss: -0.8850 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.8995 - negative_correlation_loss: -0.9030 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8995 - negative_correlation_loss: -0.9029 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8878\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 5s 49ms/step - loss: -0.8996 - negative_correlation_loss: -0.9030 - val_loss: -0.8837 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.8996 - negative_correlation_loss: -0.9031 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8876\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8998 - negative_correlation_loss: -0.9032 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9000 - negative_correlation_loss: -0.9033 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 5s 57ms/step - loss: -0.9000 - negative_correlation_loss: -0.9033 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9000 - negative_correlation_loss: -0.9033 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 5s 53ms/step - loss: -0.9000 - negative_correlation_loss: -0.9034 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.8999 - negative_correlation_loss: -0.9033 - val_loss: -0.8843 - val_negative_correlation_loss: -0.8873\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 5s 54ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8851 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 5s 53ms/step - loss: -0.9001 - negative_correlation_loss: -0.9034 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8890\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9003 - negative_correlation_loss: -0.9036 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8875\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 5s 56ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8887\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9002 - negative_correlation_loss: -0.9035 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9005 - negative_correlation_loss: -0.9036 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8885\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9007 - negative_correlation_loss: -0.9039 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8874\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9009 - negative_correlation_loss: -0.9041 - val_loss: -0.8864 - val_negative_correlation_loss: -0.8892\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9006 - negative_correlation_loss: -0.9038 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 5s 58ms/step - loss: -0.9009 - negative_correlation_loss: -0.9040 - val_loss: -0.8862 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 5s 53ms/step - loss: -0.9008 - negative_correlation_loss: -0.9040 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8884\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9009 - negative_correlation_loss: -0.9039 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8876\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9009 - negative_correlation_loss: -0.9040 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9011 - negative_correlation_loss: -0.9040 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8869\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9010 - negative_correlation_loss: -0.9039 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9012 - negative_correlation_loss: -0.9043 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 5s 57ms/step - loss: -0.9011 - negative_correlation_loss: -0.9041 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8895\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 5s 51ms/step - loss: -0.9012 - negative_correlation_loss: -0.9041 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8880\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 5s 50ms/step - loss: -0.9012 - negative_correlation_loss: -0.9042 - val_loss: -0.8855 - val_negative_correlation_loss: -0.8883\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 5s 52ms/step - loss: -0.9014 - negative_correlation_loss: -0.9044 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 14:56:32.709137: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Fold 0, correlation =  0.88977\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 6s 53ms/step - loss: -0.8065 - negative_correlation_loss: -0.8228 - val_loss: -0.8454 - val_negative_correlation_loss: -0.8584\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8551 - negative_correlation_loss: -0.8655 - val_loss: -0.8684 - val_negative_correlation_loss: -0.8773\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 5s 51ms/step - loss: -0.8765 - negative_correlation_loss: -0.8842 - val_loss: -0.8783 - val_negative_correlation_loss: -0.8851\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8841 - negative_correlation_loss: -0.8902 - val_loss: -0.8824 - val_negative_correlation_loss: -0.8881\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8879 - negative_correlation_loss: -0.8934 - val_loss: -0.8853 - val_negative_correlation_loss: -0.8908\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8904 - negative_correlation_loss: -0.8956 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8921\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8913 - negative_correlation_loss: -0.8963 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8920\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8923 - negative_correlation_loss: -0.8970 - val_loss: -0.8868 - val_negative_correlation_loss: -0.8914\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8931 - negative_correlation_loss: -0.8976 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8923\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8936 - negative_correlation_loss: -0.8980 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8919\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8938 - negative_correlation_loss: -0.8981 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8940 - negative_correlation_loss: -0.8983 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8930\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8878 - val_negative_correlation_loss: -0.8920\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 6s 60ms/step - loss: -0.8944 - negative_correlation_loss: -0.8986 - val_loss: -0.8886 - val_negative_correlation_loss: -0.8927\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8947 - negative_correlation_loss: -0.8988 - val_loss: -0.8854 - val_negative_correlation_loss: -0.8894\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8952 - negative_correlation_loss: -0.8991 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 5s 56ms/step - loss: -0.8954 - negative_correlation_loss: -0.8993 - val_loss: -0.8897 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8956 - negative_correlation_loss: -0.8994 - val_loss: -0.8901 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8957 - negative_correlation_loss: -0.8995 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8955 - negative_correlation_loss: -0.8994 - val_loss: -0.8891 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8957 - negative_correlation_loss: -0.8995 - val_loss: -0.8885 - val_negative_correlation_loss: -0.8923\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8957 - negative_correlation_loss: -0.8995 - val_loss: -0.8880 - val_negative_correlation_loss: -0.8918\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8962 - negative_correlation_loss: -0.8998 - val_loss: -0.8893 - val_negative_correlation_loss: -0.8929\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8962 - negative_correlation_loss: -0.8998 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8943\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 5s 58ms/step - loss: -0.8965 - negative_correlation_loss: -0.9000 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8944\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 6s 63ms/step - loss: -0.8964 - negative_correlation_loss: -0.9000 - val_loss: -0.8902 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8963 - negative_correlation_loss: -0.8999 - val_loss: -0.8902 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8962 - negative_correlation_loss: -0.8999 - val_loss: -0.8889 - val_negative_correlation_loss: -0.8926\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8967 - negative_correlation_loss: -0.9002 - val_loss: -0.8900 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8916 - val_negative_correlation_loss: -0.8951\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8970 - negative_correlation_loss: -0.9004 - val_loss: -0.8901 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8968 - negative_correlation_loss: -0.9002 - val_loss: -0.8900 - val_negative_correlation_loss: -0.8935\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: -0.8968 - negative_correlation_loss: -0.9003 - val_loss: -0.8904 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8969 - negative_correlation_loss: -0.9004 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8943\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8972 - negative_correlation_loss: -0.9005 - val_loss: -0.8903 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 5s 52ms/step - loss: -0.8972 - negative_correlation_loss: -0.9006 - val_loss: -0.8909 - val_negative_correlation_loss: -0.8942\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8972 - negative_correlation_loss: -0.9006 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8938\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8973 - negative_correlation_loss: -0.9006 - val_loss: -0.8899 - val_negative_correlation_loss: -0.8932\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 6s 60ms/step - loss: -0.8975 - negative_correlation_loss: -0.9008 - val_loss: -0.8914 - val_negative_correlation_loss: -0.8947\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 6s 61ms/step - loss: -0.8976 - negative_correlation_loss: -0.9009 - val_loss: -0.8904 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 5s 57ms/step - loss: -0.8976 - negative_correlation_loss: -0.9008 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8941\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8976 - negative_correlation_loss: -0.9009 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8941\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 5s 55ms/step - loss: -0.8979 - negative_correlation_loss: -0.9011 - val_loss: -0.8907 - val_negative_correlation_loss: -0.8939\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8979 - negative_correlation_loss: -0.9010 - val_loss: -0.8925 - val_negative_correlation_loss: -0.8956\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 5s 59ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8912 - val_negative_correlation_loss: -0.8943\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8980 - negative_correlation_loss: -0.9011 - val_loss: -0.8906 - val_negative_correlation_loss: -0.8937\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8980 - negative_correlation_loss: -0.9011 - val_loss: -0.8908 - val_negative_correlation_loss: -0.8940\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8980 - negative_correlation_loss: -0.9012 - val_loss: -0.8913 - val_negative_correlation_loss: -0.8945\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 5s 53ms/step - loss: -0.8982 - negative_correlation_loss: -0.9013 - val_loss: -0.8905 - val_negative_correlation_loss: -0.8936\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 5s 54ms/step - loss: -0.8983 - negative_correlation_loss: -0.9013 - val_loss: -0.8912 - val_negative_correlation_loss: -0.8943\n",
      "model saved\n",
      "Fold 1, correlation =  0.89563\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8031 - negative_correlation_loss: -0.8192 - val_loss: -0.8405 - val_negative_correlation_loss: -0.8528\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8581 - negative_correlation_loss: -0.8680 - val_loss: -0.8635 - val_negative_correlation_loss: -0.8717\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8766 - negative_correlation_loss: -0.8839 - val_loss: -0.8736 - val_negative_correlation_loss: -0.8798\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8844 - negative_correlation_loss: -0.8902 - val_loss: -0.8795 - val_negative_correlation_loss: -0.8848\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 6s 60ms/step - loss: -0.8888 - negative_correlation_loss: -0.8939 - val_loss: -0.8823 - val_negative_correlation_loss: -0.8870\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8909 - negative_correlation_loss: -0.8957 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8890\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8922 - negative_correlation_loss: -0.8967 - val_loss: -0.8844 - val_negative_correlation_loss: -0.8886\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8930 - negative_correlation_loss: -0.8973 - val_loss: -0.8848 - val_negative_correlation_loss: -0.8889\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8933 - negative_correlation_loss: -0.8975 - val_loss: -0.8836 - val_negative_correlation_loss: -0.8876\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8939 - negative_correlation_loss: -0.8980 - val_loss: -0.8841 - val_negative_correlation_loss: -0.8879\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8943 - negative_correlation_loss: -0.8982 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8883\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8945 - negative_correlation_loss: -0.8984 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8947 - negative_correlation_loss: -0.8986 - val_loss: -0.8860 - val_negative_correlation_loss: -0.8898\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8947 - negative_correlation_loss: -0.8986 - val_loss: -0.8847 - val_negative_correlation_loss: -0.8885\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8949 - negative_correlation_loss: -0.8988 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8951 - negative_correlation_loss: -0.8988 - val_loss: -0.8846 - val_negative_correlation_loss: -0.8882\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8950 - negative_correlation_loss: -0.8988 - val_loss: -0.8870 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8953 - negative_correlation_loss: -0.8990 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8953 - negative_correlation_loss: -0.8991 - val_loss: -0.8859 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8953 - negative_correlation_loss: -0.8990 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8897\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8954 - negative_correlation_loss: -0.8992 - val_loss: -0.8849 - val_negative_correlation_loss: -0.8885\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8959 - negative_correlation_loss: -0.8994 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 6s 58ms/step - loss: -0.8963 - negative_correlation_loss: -0.8998 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8903\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8961 - negative_correlation_loss: -0.8997 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8961 - negative_correlation_loss: -0.8996 - val_loss: -0.8857 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8962 - negative_correlation_loss: -0.8997 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8900\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8962 - negative_correlation_loss: -0.8997 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8896\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8961 - negative_correlation_loss: -0.8996 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8892\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 6s 59ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8845 - val_negative_correlation_loss: -0.8877\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8965 - negative_correlation_loss: -0.8999 - val_loss: -0.8858 - val_negative_correlation_loss: -0.8891\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: -0.8967 - negative_correlation_loss: -0.9000 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8894\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8967 - negative_correlation_loss: -0.9001 - val_loss: -0.8866 - val_negative_correlation_loss: -0.8899\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 5s 55ms/step - loss: -0.8970 - negative_correlation_loss: -0.9003 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8968 - negative_correlation_loss: -0.9001 - val_loss: -0.8861 - val_negative_correlation_loss: -0.8893\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 6s 60ms/step - loss: -0.8970 - negative_correlation_loss: -0.9003 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8906\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8969 - negative_correlation_loss: -0.9003 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8970 - negative_correlation_loss: -0.9003 - val_loss: -0.8874 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8971 - negative_correlation_loss: -0.9004 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8907\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8971 - negative_correlation_loss: -0.9003 - val_loss: -0.8871 - val_negative_correlation_loss: -0.8903\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8873 - val_negative_correlation_loss: -0.8902\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 6s 59ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8895\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8887 - val_negative_correlation_loss: -0.8917\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8974 - negative_correlation_loss: -0.9006 - val_loss: -0.8883 - val_negative_correlation_loss: -0.8914\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8974 - negative_correlation_loss: -0.9005 - val_loss: -0.8869 - val_negative_correlation_loss: -0.8899\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8974 - negative_correlation_loss: -0.9006 - val_loss: -0.8865 - val_negative_correlation_loss: -0.8895\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8975 - negative_correlation_loss: -0.9006 - val_loss: -0.8879 - val_negative_correlation_loss: -0.8909\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 6s 61ms/step - loss: -0.8977 - negative_correlation_loss: -0.9007 - val_loss: -0.8872 - val_negative_correlation_loss: -0.8901\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8978 - negative_correlation_loss: -0.9008 - val_loss: -0.8875 - val_negative_correlation_loss: -0.8904\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: -0.8979 - negative_correlation_loss: -0.9009 - val_loss: -0.8876 - val_negative_correlation_loss: -0.8905\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: -0.8978 - negative_correlation_loss: -0.9009 - val_loss: -0.8867 - val_negative_correlation_loss: -0.8896\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "model saved\n",
      "Fold 2, correlation =  0.89179\n",
      "\u001b[32m\u001b[1mMean corr = 0.89239\u001b[0m\n",
      "\u001b[34m\u001b[1mOof corr   = 0.89238\u001b[0m\n",
      "CPU times: user 33min 27s, sys: 1min 23s, total: 34min 51s\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 13 min 44 s\n",
    "VERBOSE = 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EPOCHS = 50 \n",
    "N_SPLITS = 3\n",
    "\n",
    "pred_train = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "score_list = []\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "score_list = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(X, groups=meta.donor)):\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_tr = X[idx_tr]\n",
    "    y_tr = Y[idx_tr]\n",
    "    X_va = X[idx_va]\n",
    "    y_va = Y[idx_va]\n",
    "\n",
    "    lr = ReduceLROnPlateau(\n",
    "                    monitor = \"val_loss\",\n",
    "                    factor = 0.9, \n",
    "                    patience = 4, \n",
    "                    verbose = VERBOSE)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "                    monitor = \"val_loss\",\n",
    "                    patience = 40, \n",
    "                    verbose = VERBOSE,\n",
    "                    mode = \"min\", \n",
    "                    restore_best_weights = True)\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath = './citeseq',\n",
    "                    save_weights_only = True,\n",
    "                    monitor = 'val_loss',\n",
    "                    mode = 'min',\n",
    "                    save_best_only = True)\n",
    "\n",
    "    callbacks = [\n",
    "                    lr, \n",
    "                    es, \n",
    "                    model_checkpoint_callback\n",
    "                    ]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=LR_START),\n",
    "                metrics = [negative_correlation_loss],\n",
    "                loss = negative_correlation_loss\n",
    "                 )\n",
    "    # Training\n",
    "    model.fit(\n",
    "                X_tr,\n",
    "                y_tr, \n",
    "                validation_data=(\n",
    "                                X_va,\n",
    "                                y_va), \n",
    "                epochs = EPOCHS,\n",
    "                verbose = VERBOSE,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "\n",
    "    del X_tr, y_tr \n",
    "    gc.collect()\n",
    "    \n",
    "    model.load_weights('./citeseq')\n",
    "    model.save(f\"./submissions/model_{fold}\")\n",
    "    print('model saved')\n",
    "    \n",
    "    #  Model validation\n",
    "    y_va_pred = model.predict(X_va)\n",
    "    corrscore = correlation_score(y_va, y_va_pred)\n",
    "    pred_train[idx_va] = y_va_pred\n",
    "    \n",
    "    print(f\"Fold {fold}, correlation =  {corrscore:.5f}\")\n",
    "    del X_va, y_va, y_va_pred\n",
    "    gc.collect()\n",
    "    score_list.append(corrscore)\n",
    "\n",
    "# Show overall score\n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}Mean corr = {np.array(score_list).mean():.5f}{Style.RESET_ALL}\")\n",
    "score_total = correlation_score(Y, pred_train)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Oof corr   = {score_total:.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f13290",
   "metadata": {
    "papermill": {
     "duration": 0.485373,
     "end_time": "2022-12-22T15:05:34.619303",
     "exception": false,
     "start_time": "2022-12-22T15:05:34.133930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed29733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T15:05:35.514601Z",
     "iopub.status.busy": "2022-12-22T15:05:35.513771Z",
     "iopub.status.idle": "2022-12-22T15:05:55.118071Z",
     "shell.execute_reply": "2022-12-22T15:05:55.117236Z"
    },
    "papermill": {
     "duration": 20.029774,
     "end_time": "2022-12-22T15:05:55.120842",
     "exception": false,
     "start_time": "2022-12-22T15:05:35.091068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with fold 0\n",
      "Predicting with fold 1\n",
      "Predicting with fold 2\n",
      "CPU times: user 30.1 s, sys: 3.92 s, total: 34 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Around 20 s\n",
    "\n",
    "test_pred = np.zeros((len(Xt), 140), dtype=np.float32)\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"Predicting with fold {fold}\")\n",
    "    model = load_model(f\"./submissions/model_{fold}\",\n",
    "                       custom_objects={'negative_correlation_loss': negative_correlation_loss})\n",
    "    test_pred += model.predict(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e173c",
   "metadata": {
    "papermill": {
     "duration": 0.430619,
     "end_time": "2022-12-22T15:05:56.039641",
     "exception": false,
     "start_time": "2022-12-22T15:05:55.609022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save submission by merging with multiome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a66b2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-22T15:05:56.888113Z",
     "iopub.status.busy": "2022-12-22T15:05:56.887606Z",
     "iopub.status.idle": "2022-12-22T15:08:59.562884Z",
     "shell.execute_reply": "2022-12-22T15:08:59.553423Z"
    },
    "papermill": {
     "duration": 183.692084,
     "end_time": "2022-12-22T15:09:00.154924",
     "exception": false,
     "start_time": "2022-12-22T15:05:56.462840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id\n",
       "0          -302.512115\n",
       "1          -290.504913\n",
       "2          -245.542084\n",
       "3           206.750916\n",
       "4           303.330536\n",
       "               ...    \n",
       "65744175     14.890625\n",
       "65744176      0.086182\n",
       "65744177      0.116577\n",
       "65744178      2.857422\n",
       "65744179     12.351562\n",
       "Name: target, Length: 65744180, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 3.49 s, total: 2min 50s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 41s\n",
    "\n",
    "# Merge with multiome\n",
    "submission = pd.read_csv(multi_ome_only_file,index_col='row_id', squeeze=True)\n",
    "submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n",
    "assert not submission.isna().any()\n",
    "\n",
    "submission.to_csv('submission_full_m256_c64.csv')\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1414.659926,
   "end_time": "2022-12-22T15:09:04.276157",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-22T14:45:29.616231",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
